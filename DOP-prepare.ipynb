{
 "metadata": {
  "name": "",
  "signature": "sha256:23ac26e8e45fee8175021da7c5c67a883242fb916191b508ad52ed55b2c23652"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
      "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
      "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "from pyparsing import nestedExpr\n",
      "from functools import reduce\n",
      "\n",
      "data_dir = '/Users/dirk/Dropbox/DANS/current/projects/etcbc/DOP/'\n",
      "bin_frags_file = 'dop.fragments'\n",
      "mul_frags_file = 'mdop.fragments'\n",
      "sort_frags_file = 'sdop.fragments'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reshape(tree):\n",
      "    if len(tree) == 1: return reshape(tree[0])[0]\n",
      "    label = tree[0]\n",
      "    rests = tree[1:]\n",
      "    rrests = reduce(lambda x,y: x+y, [reshape(rest) if type(rest) == list else [rest] for rest in rests], [])\n",
      "    if '|' in label: \n",
      "        return rrests\n",
      "    else: return [(label, rrests)]\n",
      "    \n",
      "def render(tree):\n",
      "    result = ''\n",
      "    if len(tree) == 1: return tree[0][0]\n",
      "    (label, children) = tree\n",
      "    (rlabel, num) = label.split('_', 1) if '_' in label else (label, '')\n",
      "    return '({} {})'.format(rlabel, ' '.join([render(child) for child in children]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent1 = '''\n",
      "(C (C|<CP> (CP (cj 0)) (C|<CP,VP> (VP (vb 1)) (C|<VP,PP> (PP (pp 2)) (C|<PP,NP> (NP (n 3)) (C|<NP,PP> (PP (PP|<pp> (pp 4) (PP|<pp,SU> (SU (n 5)) (PP|<SU,SU> (SU 6)))))))))))\t\u05d5      \t16\n",
      "'''\n",
      "\n",
      "sent2 = '''\n",
      "(S (S|<C> (C_3 0 2 4) (S|<C,Attr>_2 1 3)))\n",
      "'''\n",
      "sent = sent2\n",
      "\n",
      "tree = nestedExpr('(',')').parseString(sent).asList()\n",
      "print(tree)\n",
      "rtree = reshape(tree)\n",
      "print(rtree)\n",
      "print(render(rtree))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['S', ['S|<C>', ['C_3', '0', '2', '4'], ['S|<C,Attr>_2', '1', '3']]]]\n",
        "('S', [('C_3', ['0', '2', '4']), '1', '3'])\n",
        "(S (C 0 2 4) 1 3)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following takes a really long time, 343589 fragments to do."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "datain = open(\"{}/{}\".format(data_dir, bin_frags_file))\n",
      "dataout = open(\"{}/{}\".format(data_dir, mul_frags_file), 'w')\n",
      "nl = 0\n",
      "chunk = 1000\n",
      "sn = 0\n",
      "for line in datain:\n",
      "    nl += 1\n",
      "    sn += 1\n",
      "    if sn == chunk:\n",
      "        sn = 0\n",
      "        sys.stderr.write(\"{} lines\\n\".format(nl))\n",
      "    (sent, text, num) = line.rstrip().split('\\t')\n",
      "    tree = nestedExpr('(',')').parseString(sent).asList()\n",
      "    try:\n",
      "        rtree = reshape(tree)\n",
      "        dataout.write(\"{}\\t{}\\t{}\\n\".format(render(rtree), text, num))\n",
      "    except TypeError as e:\n",
      "        print(\"{} at input line {}\".format(e, nl))\n",
      "datain.close\n",
      "dataout.close\n",
      "print(\"{} lines\".format(nl))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "1000 lines\n",
        "2000 lines\n"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have multiway trees again."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sort -k3nr -t $'\\t' mtest.fragments > stest.fragments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "import laf\n",
      "from laf.fabric import LafFabric\n",
      "from etcbc.preprocess import prepare\n",
      "from etcbc.mql import MQL\n",
      "fabric = LafFabric()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.1.1\n",
        "http://laf-fabric.readthedocs.org/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API = fabric.load('bhs3.txt.hdr', '--', 'dop', {\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": ('''\n",
      "        oid otype monads\n",
      "        text_plain\n",
      "        surface_consonants\n",
      "        part_of_speech\n",
      "        clause_constituent_relation phrase_type\n",
      "        verse_label\n",
      "    ''','''\n",
      "    '''),\n",
      "    \"prepare\": prepare,\n",
      "}, verbose='NORMAL')\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s INFO: DATA COMPILED AT: 2014-04-05T09-12-34\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.77s LOGFILE=/Users/dirk/laf-fabric-data/etcbc-bhs3/tasks/bhs3.txt.hdr/dop/__log__dop.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.62s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX -- FOR TASK dop\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_types = set()\n",
      "for n in NN(test=F.otype.v, value='phrase'):\n",
      "    phrase_types.add(F.phrase_type.v(n))\n",
      "phrase_types"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "{'AdjP',\n",
        " 'AdvP',\n",
        " 'CP',\n",
        " 'DPrP',\n",
        " 'IPrP',\n",
        " 'InjP',\n",
        " 'InrP',\n",
        " 'NP',\n",
        " 'NegP',\n",
        " 'PP',\n",
        " 'PPrP',\n",
        " 'PrNP',\n",
        " 'VP'}"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clause_types = set()\n",
      "for n in NN(test=F.otype.v, value='clause'):\n",
      "    clause_types.add(F.clause_constituent_relation.v(n))\n",
      "clause_types"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "{'Adju',\n",
        " 'Attr',\n",
        " 'Cmpl',\n",
        " 'CoVo',\n",
        " 'Coor',\n",
        " 'Objc',\n",
        " 'Pred',\n",
        " 'Resu',\n",
        " 'RgRc',\n",
        " 'Subj',\n",
        " 'none'}"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "relevant_nodes = [\n",
      "    (\"word\", '', True),\n",
      "    (\"subphrase\", 'SU', True),\n",
      "    (\"phrase_atom\", 'Pa', False),\n",
      "    (\"phrase\", 'P', True),\n",
      "    (\"clause_atom\", 'Ca', False),\n",
      "    (\"clause\", 'C', True),\n",
      "    (\"sentence_atom\", 'Sa', False),\n",
      "    (\"sentence\", 'S', True),\n",
      "]\n",
      "\n",
      "pos_table = {\n",
      " 'adjective': 'aj',\n",
      " 'adverb': 'av',\n",
      " 'article': 'dt',\n",
      " 'conjunction': 'cj',\n",
      " 'interjection': 'ij',\n",
      " 'interrogative': 'ir',\n",
      " 'negative': 'ng',\n",
      " 'noun': 'n',\n",
      " 'preposition': 'pp',\n",
      " 'pronoun': 'pr',\n",
      " 'verb': 'vb',\n",
      "}\n",
      "\n",
      "long_name = {}\n",
      "dtype = {}\n",
      "for (lname, abb, bl) in relevant_nodes:\n",
      "    long_name[abb] = lname\n",
      "    dtype[abb] = 'con'\n",
      "for (lname, abb) in pos_table.items():\n",
      "    long_name[abb] = lname\n",
      "    dtype[abb] = 'pos'\n",
      "for pt in phrase_types:\n",
      "    long_name[pt] = pt\n",
      "    dtype[pt] = 'phr'\n",
      "for ctr in clause_types:\n",
      "    ct = ctr\n",
      "    if ct == \"none\": ct = 'C'\n",
      "    long_name[ct] = ct\n",
      "    dtype[ct] = 'cls'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make a mapping between the text_plain and the surface_consonants features of words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sur2txt = collections.defaultdict(lambda: set())\n",
      "txt2sur = collections.defaultdict(lambda: set())\n",
      "nw = 0\n",
      "for n in NN(test=F.otype.v, value='word'):\n",
      "    nw += 1\n",
      "    sur = F.surface_consonants.v(n)\n",
      "    nsur = sur.replace('_', '')\n",
      "    txt = F.text_plain.v(n)\n",
      "    ntxt = txt.replace('\u05be','').replace(' ', '').replace('\u05df', '\u05e0').replace('\u05dd', '\u05de')\n",
      "    sur2txt[nsur].add(ntxt)\n",
      "    txt2sur[ntxt].add(nsur)\n",
      "\n",
      "print(\"NW={}\".format(nw))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NW=426499\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ns = 0\n",
      "corr_sur = {}\n",
      "for sur in sorted(sur2txt):\n",
      "    if len(sur2txt[sur]) > 1:\n",
      "        corr_sur[sur] = {x for x in sur2txt[sur] if len(x) == len(sur)}\n",
      "        print(\"{} = {}; corr = {}\".format(sur, ', '.join(sorted(sur2txt[sur])), ', '.join(corr_sur[sur])))\n",
      "        ns += 1\n",
      "nt = 0\n",
      "corr_txt = {}\n",
      "for txt in sorted(txt2sur):\n",
      "    if len(txt2sur[txt]) > 1:\n",
      "        corr_txt[txt] = {x for x in txt2sur[txt] if len(x) == len(txt)}\n",
      "        print(\"{} = {}; corr = {}\".format(txt, ', '.join(sorted(txt2sur[txt])), ', '.join(corr_txt[txt])))\n",
      "        nt += 1\n",
      "print(\"NS={}; NT={}\".format(ns, nt))\n",
      "\n",
      "sur2txt.update(corr_sur)\n",
      "txt2sur.update(corr_txt)\n",
      "del txt2sur['']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "''",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-11-ab9c2a50b991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msur2txt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_sur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtxt2sur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtxt2sur\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mKeyError\u001b[0m: ''"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NS=0; NT=0\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sur_txt = dict([(x[0], list(x[1])[0]) for x in sur2txt.items()])\n",
      "txt_sur = dict([(x[0], list(x[1])[0]) for x in txt2sur.items()])\n",
      "txt_sur[''] = ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "line = '''(C (CP (cj 0)) (NegP (ng 1)) 2)\t\u05d5 \u05dc\u05d0 \t1215\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_mql(line):\n",
      "    (fragstr, text, num) = line.rstrip().split('\\t')\n",
      "    words = [word[::-1] for word in text.split(' ')]\n",
      "    frag = nestedExpr('(',')').parseString(fragstr).asList()\n",
      "    print(frag[0])\n",
      "    return (trans_mql(frag[0], words, 0), words, num)\n",
      "\n",
      "def trans_mql(rep, words, indent):\n",
      "    if type(rep) == list:\n",
      "        label = long_name[rep[0]]\n",
      "        dt = dtype[rep[0]]\n",
      "        n = rep[1]\n",
      "        return '{ind}[word part_of_speech = \"{}\" AND surface_consonants = \"{}\"]\\n'.format(\n",
      "                label, txt_sur[words[int(n)]], ind = ' ' * indent\n",
      "        ) if dt == 'pos' else '{ind}[{}\\n{}{ind}]\\n'.format(\n",
      "                label, '{ind}\\n'.format(ind=' ' * indent).join([trans_mql(child, words, indent+1) for child in rep[1:]]),\n",
      "                ind =' ' * indent\n",
      "        ) if dt == 'con' else  '{ind}[phrase phrase_type=\"{}\"\\n{}{ind}]\\n'.format(\n",
      "                label, '{ind}\\n'.format(ind=' ' * indent).join([trans_mql(child, words, indent+1) for child in rep[1:]]),\n",
      "                ind =' ' * indent\n",
      "        ) if dt == 'phr' else  '{ind}[clause clause_contituent_relation=\"{}\"\\n{}{ind}]\\n'.format(\n",
      "                label, '{ind}\\n'.format(ind=' ' * indent).join([trans_mql(child, words, indent+1) for child in rep[1:]]),\n",
      "                ind =' ' * indent\n",
      "        ) if dt == 'cls' else 'XXX'\n",
      "    else: \n",
      "        w = words[int(rep)]\n",
      "        return '{ind}[word{}]\\n'.format(\n",
      "                ' surface_consonants = \"{}\"'.format(txt_sur[w]) if w != '' else '', ind = ' ' * indent\n",
      "          )\n",
      "        \n",
      "\n",
      "mquery = make_mql(line)[0]\n",
      "print(mquery)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['C', ['CP', ['cj', '0']], ['NegP', ['ng', '1']], '2']\n",
        "[clause clause_contituent_relation=\"C\"\n",
        " [phrase phrase_type=\"CP\"\n",
        "  [word part_of_speech = \"conjunction\" AND surface_consonants = \"W\"]\n",
        " ]\n",
        "\n",
        " [phrase phrase_type=\"NegP\"\n",
        "  [word part_of_speech = \"negative\" AND surface_consonants = \">L\"]\n",
        " ]\n",
        "\n",
        " [word]\n",
        "]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mquery = '''\n",
      "[clause clause_contituent_relation=\"C\"\n",
      " [phrase phrase_type=\"CP\"\n",
      "  [word part_of_speech = \"conjunction\" AND surface_consonants = \"W\"]\n",
      " ]\n",
      "\n",
      " [phrase phrase_type=\"NegP\"\n",
      "  [word part_of_speech = \"negative\" AND surface_consonants = \"L>\"]\n",
      " ]\n",
      "]\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q = MQL(API)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sheaf = Q.mql(mquery)\n",
      "print(sheaf.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(sheaf.compact(F.surface_consonants.v))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "'NoneType' object is not iterable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-30-2b11de905104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheaf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurface_consonants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Users/dirk/software/anaconda/lib/python3.3/site-packages/etcbc/mql.py\u001b[0m in \u001b[0;36mcompact\u001b[0;34m(self, monadrep)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msheaf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonadrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMQL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_sheaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonadrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mcompact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonadrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mMQL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compact_sheaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonadrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mMQL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results_sheaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompact_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonadrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mMQL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compact_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMQL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results_sheaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonadrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/dirk/software/anaconda/lib/python3.3/site-packages/etcbc/mql.py\u001b[0m in \u001b[0;36m_compact_sheaf\u001b[0;34m(data, level, monadrep)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compact_sheaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonadrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m' -- '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMQL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compact_straw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonadrep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compact_straw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonadrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}