{
 "metadata": {
  "name": "",
  "signature": "sha256:9329a213217a7009dba816c33a56d0acf775daef77a386ff9c8d523391a87bce"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
      "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
      "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature docs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a general purpose tool to get acquainted with the features in the LAF version of the Hebrew Database"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "\n",
      "import pandas\n",
      "import matplotlib.pyplot as plt\n",
      "from IPython.display import display\n",
      "pandas.set_option('display.notebook_repr_html', True)\n",
      "%matplotlib inline\n",
      "\n",
      "from laf.fabric import LafFabric\n",
      "import etcbc\n",
      "from etcbc.featuredoc import FeatureDoc\n",
      "\n",
      "fabric = LafFabric()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.2.8\n",
        "http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Choose your features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Specifiy the features you want to study.\n",
      "This notebook only offers to study the features in the *ft* namespace.\n",
      "\n",
      "Do this by providing a list of features to the *study specification* below.\n",
      "\n",
      "The requested features will be loaded, on top of the base supply of features that we need for showing examples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API = fabric.load('bhs3', '--', 'feature-doc', {\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": (\"\",\"\"),\n",
      "    \"primary\": False,\n",
      "})\n",
      "\n",
      "doc = FeatureDoc(fabric, {\n",
      "    'features': [\n",
      "        'gender',\n",
      "        'number',\n",
      "        'person',\n",
      "        'suffix_gender',\n",
      "        'suffix_number',\n",
      "        'suffix_person',\n",
      "        'locative',\n",
      "        'tense',\n",
      "        'noun_type',\n",
      "        'pronoun_type',\n",
      "        'lexical_set',\n",
      "        'part_of_speech',\n",
      "        'phrase_dependent_part_of_speech',\n",
      "        'phrase_type',\n",
      "        'phrase_function',\n",
      "        'clause_constituent_relation',\n",
      "        'clause_atom_relation',\n",
      "        'clause_atom_type',\n",
      "        'domain',\n",
      "        'text_type',\n",
      "        'embedding_domain',\n",
      "    ],\n",
      "    'absence_values': set((\n",
      "        'none',\n",
      "        'unknown',\n",
      "        'Unkn',\n",
      "    )),\n",
      "    'VALUE_THRESHOLD': 50,\n",
      "})\n",
      "\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s INFO: DATA COMPILED AT: 2014-04-18T18-24-37\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.05s LOGFILE=C:\\Users\\Gino/laf-fabric-data/bhs3/tasks/feature-doc/__log__feature-doc.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.05s INFO: DATA LOADED FROM SOURCE bhs3 AND ANNOX -- FOR TASK feature-doc\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s INFO: DATA COMPILED AT: 2014-04-18T18-24-37\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    26s LOGFILE=C:\\Users\\Gino/laf-fabric-data/bhs3/tasks/feature-doc/__log__feature-doc.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    26s INFO: DATA LOADED FROM SOURCE bhs3 AND ANNOX -- FOR TASK feature-doc\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API = fabric.load('calap', '--', 'feature-doc', {\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": (\"\",\"\"),\n",
      "    \"primary\": False,\n",
      "})\n",
      "\n",
      "doc = FeatureDoc(fabric, {\n",
      "    'features': [\n",
      "        'gender',\n",
      "        'tense',\n",
      "        'psp',\n",
      "        'phrase_function',\n",
      "        'phrase_type',\n",
      "        'surface_consonants',\n",
      "    ],\n",
      "    'absence_values': set((\n",
      "        'none',\n",
      "        'unknown',\n",
      "        'Unkn',\n",
      "    )),\n",
      "    'VALUE_THRESHOLD': 50,\n",
      "})\n",
      "\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.67s INFO: DATA COMPILED AT: 2014-05-06T14-03-13\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.81s LOGFILE=/Users/dirk/laf-fabric-data/calap/tasks/feature-doc/__log__feature-doc.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.81s INFO: DATA LOADED FROM SOURCE calap AND ANNOX -- FOR TASK feature-doc\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: DATA COMPILED AT: 2014-05-06T14-03-13\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.20s LOGFILE=/Users/dirk/laf-fabric-data/calap/tasks/feature-doc/__log__feature-doc.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.20s INFO: DATA LOADED FROM SOURCE calap AND ANNOX -- FOR TASK feature-doc\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you want to know the set of available features, you can inspect it by:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(API['F_all'], API['FE_all'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "([('shebanq',\n",
        "   ['db.maxmonad',\n",
        "    'db.minmonad',\n",
        "    'db.monads',\n",
        "    'db.oid',\n",
        "    'db.otype',\n",
        "    'ft.aramaic_definite_article',\n",
        "    'ft.clause_atom_number',\n",
        "    'ft.clause_atom_relation',\n",
        "    'ft.clause_atom_relation_daughter_tense',\n",
        "    'ft.clause_atom_relation_kind',\n",
        "    'ft.clause_atom_relation_mother_tense',\n",
        "    'ft.clause_atom_relation_preposition_class',\n",
        "    'ft.clause_atom_type',\n",
        "    'ft.clause_constituent_relation',\n",
        "    'ft.clause_type',\n",
        "    'ft.determination',\n",
        "    'ft.domain',\n",
        "    'ft.embedding_domain',\n",
        "    'ft.gender',\n",
        "    'ft.graphical_aramaic_definite_article',\n",
        "    'ft.graphical_aramaic_definite_article_plain',\n",
        "    'ft.graphical_lexeme',\n",
        "    'ft.graphical_lexeme_utf8',\n",
        "    'ft.graphical_locative',\n",
        "    'ft.graphical_locative_plain',\n",
        "    'ft.graphical_nominal_ending',\n",
        "    'ft.graphical_nominal_ending_plain',\n",
        "    'ft.graphical_preformative',\n",
        "    'ft.graphical_preformative_plain',\n",
        "    'ft.graphical_pron_suffix',\n",
        "    'ft.graphical_pron_suffix_plain',\n",
        "    'ft.graphical_root_formation',\n",
        "    'ft.graphical_root_formation_plain',\n",
        "    'ft.graphical_verbal_ending',\n",
        "    'ft.graphical_verbal_ending_plain',\n",
        "    'ft.graphical_word',\n",
        "    'ft.indentation',\n",
        "    'ft.is_apposition',\n",
        "    'ft.language',\n",
        "    'ft.levels_of_embedding',\n",
        "    'ft.lexeme',\n",
        "    'ft.lexeme_utf8',\n",
        "    'ft.lexical_set',\n",
        "    'ft.locative',\n",
        "    'ft.noun_type',\n",
        "    'ft.number',\n",
        "    'ft.number_within_chapter',\n",
        "    'ft.number_within_clause',\n",
        "    'ft.number_within_sentence',\n",
        "    'ft.old_lexeme',\n",
        "    'ft.old_lexeme_utf8',\n",
        "    'ft.paradigmatic_nominal_ending',\n",
        "    'ft.paradigmatic_preformative',\n",
        "    'ft.paradigmatic_pron_suffix',\n",
        "    'ft.paradigmatic_root_formation',\n",
        "    'ft.paradigmatic_verbal_ending',\n",
        "    'ft.part_of_speech',\n",
        "    'ft.person',\n",
        "    'ft.phrase_atom_number',\n",
        "    'ft.phrase_atom_relation',\n",
        "    'ft.phrase_atom_type',\n",
        "    'ft.phrase_dependent_part_of_speech',\n",
        "    'ft.phrase_function',\n",
        "    'ft.phrase_type',\n",
        "    'ft.pronoun_type',\n",
        "    'ft.sentence_atom_number',\n",
        "    'ft.state',\n",
        "    'ft.stem',\n",
        "    'ft.subphrase_kind',\n",
        "    'ft.subphrase_type',\n",
        "    'ft.suffix',\n",
        "    'ft.suffix_gender',\n",
        "    'ft.suffix_number',\n",
        "    'ft.suffix_person',\n",
        "    'ft.surface_consonants',\n",
        "    'ft.surface_consonants_utf8',\n",
        "    'ft.tense',\n",
        "    'ft.text',\n",
        "    'ft.text_plain',\n",
        "    'ft.text_type',\n",
        "    'ft.vocalized_lexeme',\n",
        "    'ft.vocalized_lexeme_utf8',\n",
        "    'ft.word_number_within_book',\n",
        "    'sft.book',\n",
        "    'sft.chapter',\n",
        "    'sft.half_verse',\n",
        "    'sft.verse',\n",
        "    'sft.verse_label'])],\n",
        " [('laf', [('', 'x'), ('', 'y')]), ('shebanq', ['mother.', 'parents.'])])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now generate files with feature data. \n",
      "For each selected feature, you get a list with values, with for each value its number of occurrences.\n",
      "The values are divided into two sets: *defined values* and *absence values*.\n",
      "The latter are values such as ``none``, ``unknown``. You have to provide these values yourself by adapting the ``absence_values`` list in the study specification above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "doc.feature_doc()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 4m 11s Looking up feature values ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 5m 52s Computing results ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 5m 52s Done\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is also a summary file.\n",
      "\n",
      "For each feature it has the following columns:\n",
      "\n",
      "**Feature** name of the feature\n",
      "**val (-)**, **val (+)** value of the feature; **val (-)** contains absence values, **val (+)** contains defined values.\n",
      "**#vals** number of distinct values of this feature, split between the absence values and the defined values\n",
      "**occs** number of occurrences of this value or this feature\n",
      "**clause**, **phrase**, etc: how often the feature occurs on which type of node."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "df = pandas.read_csv(my_file('summary.txt'),sep='\\t', na_filter=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Feature</th>\n",
        "      <th>val (-)</th>\n",
        "      <th>val (+)</th>\n",
        "      <th>#vals (-)</th>\n",
        "      <th>#vals (+)</th>\n",
        "      <th>occs (-)</th>\n",
        "      <th>occs (+)</th>\n",
        "      <th>phrase (-)</th>\n",
        "      <th>phrase (+)</th>\n",
        "      <th>phrase_atom (-)</th>\n",
        "      <th>phrase_atom (+)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> is_apposition</td>\n",
        "      <td> </td>\n",
        "      <td>      </td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 526747</td>\n",
        "      <td> 0</td>\n",
        "      <td> 257109</td>\n",
        "      <td> 0</td>\n",
        "      <td> 269638</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>              </td>\n",
        "      <td> </td>\n",
        "      <td> false</td>\n",
        "      <td>  </td>\n",
        "      <td>  </td>\n",
        "      <td>  </td>\n",
        "      <td> 526747</td>\n",
        "      <td>  </td>\n",
        "      <td>       </td>\n",
        "      <td>  </td>\n",
        "      <td>       </td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>2 rows \u00d7 11 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "         Feature val (-) val (+) #vals (-) #vals (+) occs (-)  occs (+)  \\\n",
        "0  is_apposition                         0         1        0    526747   \n",
        "1                          false                                 526747   \n",
        "\n",
        "  phrase (-) phrase (+) phrase_atom (-) phrase_atom (+)  \n",
        "0          0     257109               0          269638  \n",
        "1                                                        \n",
        "\n",
        "[2 rows x 11 columns]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 100 {my_file('surface_consonants\\ values.txt')}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "head: /Users/dirk/laf-fabric-data/bhs3/tasks/feature-doc/surface_consonants values.txt: No such file or directory\r\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 100 {my_file('clause_constituent_relation\\ values.txt')}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "UNDEFINED VALUES\r\n",
        "none x 75059\r\n",
        "\r\n",
        "DEFINED VALUES\r\n",
        "Adju x 4910\r\n",
        "Attr x 4804\r\n",
        "Objc x 1066\r\n",
        "Resu x 976\r\n",
        "Coor x 908\r\n",
        "Subj x 241\r\n",
        "CoVo x 143\r\n",
        "RgRc x 114\r\n",
        "Pred x 91\r\n",
        "Cmpl x 75\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API['close']()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 01s Results directory:\n",
        "C:\\Users\\Gino/laf-fabric-data/bhs3/tasks/feature-doc\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "__log__feature-doc.txt                  294 Fri Jun  6 11:47:53 2014\n",
        "clause_atom_relation values.txt         3218 Fri Jun  6 11:49:41 2014\n",
        "clause_atom_type values.txt             407 Fri Jun  6 11:49:41 2014\n",
        "clause_constituent_relation values.txt          171 Fri Jun  6 11:49:41 2014\n",
        "domain values.txt                       110 Fri Jun  6 11:49:41 2014\n",
        "embedding_domain values.txt             121 Fri Jun  6 11:49:41 2014\n",
        "gender values.txt                       107 Fri Jun  6 11:49:41 2014\n",
        "locative values.txt                      63 Fri Jun  6 11:49:41 2014\n",
        "noun_type values.txt                     84 Fri Jun  6 11:49:41 2014\n",
        "number values.txt                       115 Fri Jun  6 11:49:41 2014\n",
        "part_of_speech values.txt               233 Fri Jun  6 11:49:41 2014\n",
        "person values.txt                       134 Fri Jun  6 11:49:41 2014\n",
        "phrase_dependent_part_of_speech values.txt          233 Fri Jun  6 11:49:41 2014\n",
        "phrase_function values.txt              423 Fri Jun  6 11:49:41 2014\n",
        "phrase_type values.txt                  200 Fri Jun  6 11:49:41 2014\n",
        "pronoun_type values.txt                 112 Fri Jun  6 11:49:41 2014\n",
        "suffix_gender values.txt                102 Fri Jun  6 11:49:41 2014\n",
        "suffix_number values.txt                 85 Fri Jun  6 11:49:41 2014\n",
        "suffix_person values.txt                117 Fri Jun  6 11:49:41 2014\n",
        "summary.txt                            7698 Fri Jun  6 11:49:41 2014\n",
        "tense values.txt                        244 Fri Jun  6 11:49:41 2014\n",
        "text_type values.txt                    816 Fri Jun  6 11:49:41 2014\n",
        "types.txt                               646 Fri Jun  6 11:49:41 2014\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}