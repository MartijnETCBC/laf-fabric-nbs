{
 "metadata": {
  "name": "",
  "signature": "sha256:5df3c57e85e454d743c828302ec046b3cc9265117a2478f54e8dd0e112dc8c2c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"right\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
      "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"right\"src=\"images/etcbc4easy-small.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Participle: data collection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Hebrew participle, active and passive, is the object of study in this notebook."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Hebrew participle is seen to function in a nominal way, as well as in a verbal way. \n",
      "Sometimes the participle even functions as a finite verb.\n",
      "\n",
      "There are indications that the usage of participles in classical Hebrew indicates a shift in syntactic patterns, either due to temporal evolution or due to geographical distribution.\n",
      "\n",
      "In order to look for the syntactic variation that is centered around the participle, we first have to collect the data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Desiderata"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(A) We want a list of participles and per occurrence we want to record:\n",
      "\n",
      "* the root consonants of the lexeme\n",
      "* the verbal stem (qal, piel, hiphil, etc)\n",
      "\n",
      "(B) For all lexemes found in this way, we also want to know\n",
      "\n",
      "* how often do they occur as verb and as noun or other part of speech type\n",
      "* for the verb occurrences: how often do the different verbal stems occur, and with what tense: perfect, imperfect, participium active, participium passive, or other\n",
      "\n",
      "(C) We want a list of particple-like forms:\n",
      "\n",
      "* forms not marked as verb, but with the vowel pattern of a particple, eg. QOHEN\n",
      "\n",
      "(D) We want the desired quantities per book"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Starting up"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "import re\n",
      "from laf.fabric import LafFabric\n",
      "from etcbc.preprocess import prepare\n",
      "fabric = LafFabric()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.4.1\n",
        "http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fabric.load('etcbc4', '--', 'participle', {\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": ('''\n",
      "        otype\n",
      "        book chapter verse label\n",
      "        g_word g_lex lex\n",
      "        sp vs vt\n",
      "    ''','''\n",
      "    '''),\n",
      "    \"primary\": False,\n",
      "})\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: USING DATA COMPILED AT: 2014-07-23T09-31-37\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.94s INFO: DATA LOADED FROM SOURCE etcbc4 AND ANNOX -- FOR TASK participle AT 2014-09-01T12-12-16\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Get all verb forms with their relevant properties"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We collect a list with all verb occurrences and store their lexeme, verbal stem, verbal tense and the current book.\n",
      "\n",
      "At the same time we also collect a list of all non-verb words and store their lexeme and part-of-speech."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_book = None\n",
      "cur_chapter = None\n",
      "cur_verse = None\n",
      "gword_occs = []\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'book':\n",
      "        cur_book = F.book.v(n)\n",
      "    elif otype == 'chapter': cur_chapter = F.chapter.v(n)\n",
      "    elif otype == 'verse': cur_verse = F.verse.v(n)\n",
      "    elif otype == 'word': \n",
      "        psp = F.sp.v(n)\n",
      "        vt = F.vt.v(n)\n",
      "        vs = F.vs.v(n)\n",
      "        glex = F.g_lex.v(n)\n",
      "        lex = F.lex.v(n).rstrip('/[=')\n",
      "        gword = F.g_word.v(n)\n",
      "        gword_occs.append((gword, glex, lex, psp, vs, vt, cur_book, cur_chapter, cur_verse))\n",
      "\n",
      "of = outfile('gwords.csv')\n",
      "for x in gword_occs:\n",
      "    of.write(\"{}\\n\".format('\\t'.join(x)))\n",
      "of.close()\n",
      "\n",
      "sys.stderr.write('{:>7} words\\n'.format(len(gword_occs)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 426555 words\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Produce derived data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now filter all occurrences where the part of speech is verb."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gverb_occs = [x for x in gword_occs if x[3] == 'verb']\n",
      "of = outfile('gverbs.csv')\n",
      "of.write('word\\tglex\\tlex\\tpsp\\tstem\\ttense\\tbook\\tchapter\\tverse\\n')\n",
      "for x in gverb_occs:\n",
      "    of.write(\"{}\\n\".format('\\t'.join(x)))\n",
      "of.close()\n",
      "\n",
      "sys.stderr.write('{:>7} verbs\\n'.format(len(gverb_occs)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  73659 verbs\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fetch other participia"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Precise search for most participle like patterns, following the paradigm tables from [Blakley](http://blakleycreative.com/jtb/HebrewGrammar.htm): [strong verb](http://blakleycreative.com/jtb/Text/Paradigms_StrongVerbConsolidation.pdf) and/or Lettinga"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HC = '[>BGDHWZXVJKLMNS<PYQRFCTkmnpy]'\n",
      "strip_dia_pat = re.compile(r'[,0-9]+')\n",
      "\n",
      "ptc_pats_src = {\n",
      "    'qal1': {\n",
      "        'ms': '{B}{HC}O{HC};{HC}{E}',\n",
      "        'mpa': '{B}{HC}O{HC}:{HC}IJ[Mm]{E}',\n",
      "        'mpc': '{B}{HC}O{HC}:{HC}EJ{E}',\n",
      "        'fs1': '{B}{HC}O{HC}E{HC}ET{E}',\n",
      "        'fs2': '{B}{HC}O{HC};{HC}@H{E}',\n",
      "        'fs3': '{B}{HC}O{HC}:{HC}@H{E}',\n",
      "        'fp': '{B}{HC}O{HC}:{HC}OWT{E}',\n",
      "    },\n",
      "    'qal2': {\n",
      "        'ms': '{B}{HC}@{HC};{HC}{E}',\n",
      "        'mpa': '{B}{HC}@{HC}:{HC}IJ[Mm]{E}',\n",
      "        'mpc': '{B}{HC}@{HC}:{HC}EJ{E}',\n",
      "        'fs': '{B}{HC}:{HC};{HC}@H{E}',\n",
      "        'fp': '{B}{HC}:{HC}:{HC}OWT{E}',\n",
      "    },\n",
      "    'qal3': {\n",
      "        'ms': '{B}{HC}@{HC}O{HC}{E}',\n",
      "        'mpa': '{B}{HC}@{HC}:{HC}IJ[Mm]{E}',\n",
      "        'mpc': '{B}{HC}@{HC}:{HC}EJ{E}',\n",
      "        'fs': '{B}{HC}:{HC}O{HC}@H{E}',\n",
      "        'fp': '{B}{HC}:{HC}:{HC}OWT{E}',\n",
      "    },\n",
      "    'nifal': {\n",
      "        'ms': '{B}N.{HC}:{HC}\\.?@{HC}{E}',\n",
      "        'mpa': '{B}N.{HC}:{HC}\\.?:{HC}IJ[Mm]{E}',\n",
      "        'mpc': '{B}N.{HC}:{HC}\\.?:{HC}EJ{E}',\n",
      "        'fs1': '{B}N.{HC}E{HC}\\.?E{HC}ET{E}',\n",
      "        'fs2': '{B}N.{HC}@{HC}\\.?@{HC}H{E}',\n",
      "        'fp': '{B}N.{HC}@{HC}\\.?@{HC}OWT{E}',\n",
      "    },\n",
      "    'piel': {\n",
      "        'ms': '{B}M:{HC}A{HC}\\.;{HC}{E}',\n",
      "        'mpa': '{B}M:{HC}A{HC}\\.:{HC}IJ[Mm]{E}',\n",
      "        'mpc': '{B}M:{HC}A{HC}\\.:{HC}EJ{E}',\n",
      "        'fs1': '{B}M:{HC}A{HC}\\.E{HC}ET{E}',\n",
      "        'fs2': '{B}M:{HC}A{HC}\\.:{HC}H{E}',\n",
      "        'fp': '{B}M:{HC}A{HC}\\.:{HC}OWT{E}',\n",
      "    },\n",
      "    'hifil': {\n",
      "        'ms': '{B}MA{HC}:{HC}\\.?IJ{HC}{E}',\n",
      "        'mpa': '{B}MA{HC}:{HC}\\.?IJ{HC}IJ[Mm]{E}',\n",
      "        'mpc': '{B}MA{HC}:{HC}\\.?IJ{HC}EJ{E}',\n",
      "        'fs1': '{B}MA{HC}:{HC}\\.E{HC}ET{E}',\n",
      "        'fs2': '{B}MA{HC}:{HC}\\.?IJ{HC}H{E}',\n",
      "        'fp': '{B}MA{HC}:{HC}\\.?IJ{HC}OWT{E}',\n",
      "    },\n",
      "    'hitpael': {\n",
      "        'ms': '{B}MIT:{HC}\\.?A{HC}\\.;{HC}{E}',\n",
      "        'mpa': '{B}MIT:{HC}\\.?A{HC}\\.:{HC}IJ[Mm]{E}',\n",
      "        'mpc': '{B}MIT:{HC}\\.?A{HC}\\.:{HC}EJ{E}',\n",
      "        'fs1': '{B}MIT:{HC}\\.?A{HC}\\.E{HC}ET{E}',\n",
      "        'fs2': '{B}MIT:{HC}\\.?A{HC}\\.:{HC}H{E}',\n",
      "        'fp': '{B}MIT:{HC}\\.?A{HC}\\.:{HC}OWT{E}',\n",
      "    },\n",
      "}\n",
      "\n",
      "ptc_pats = collections.defaultdict(lambda: collections.defaultdict(lambda: {}))\n",
      "\n",
      "for stem in ptc_pats_src:\n",
      "    for pat in ptc_pats_src[stem]:\n",
      "        ptc_pats[stem][pat]['wrd'] = re.compile(ptc_pats_src[stem][pat].format(HC=HC, B='^', E=''))\n",
      "        ptc_pats[stem][pat]['lex'] = re.compile(ptc_pats_src[stem][pat].format(HC=HC, B='', E='$'))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "px_occs = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(lambda: [])))\n",
      "px_ = collections.defaultdict(lambda: [])\n",
      "\n",
      "for (gword, glex, lex, psp, vs, vt, book, chapter, verse) in gword_occs:\n",
      "    if psp == 'verb' and vt == 'ptca': continue\n",
      "    pspx = psp if psp != 'verb' else vs+'.'+vt\n",
      "    gwordx = strip_dia_pat.sub('', gword)\n",
      "    summarize = psp != 'verb' and psp != 'nmpr'\n",
      "    for stem in ptc_pats:\n",
      "        for pat in ptc_pats[stem]:\n",
      "            if ptc_pats[stem][pat]['wrd'].search(gwordx) != None:\n",
      "                px_occs[stem][pspx]['wrd'].append((gword, glex, lex, psp, vs, vt, book, chapter, verse))\n",
      "                if summarize:\n",
      "                    px_['wrd'].append((gword, glex, lex, psp, vs, vt, book, chapter, verse))                    \n",
      "            if ptc_pats[stem][pat]['lex'].search(glex) != None:\n",
      "                px_occs[stem][pspx]['lex'].append((gword, glex, lex, psp, vs, vt, book, chapter, verse))\n",
      "                if summarize:\n",
      "                    px_['lex'].append((gword, glex, lex, psp, vs, vt, book, chapter, verse))                    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for stem in sorted(ptc_pats):\n",
      "    data = px_occs.get(stem, {})\n",
      "    for psp in data:\n",
      "        for kind in data[psp]:\n",
      "            thisdata = data[psp][kind]\n",
      "            sys.stderr.write('{:>7} {}-participium-like occurrences marked as {} ({}-based)\\n'.format(len(thisdata), stem, psp, kind))\n",
      "            of = outfile('ptcx_occs_{}_{}_{}.csv'.format(stem, psp, kind))\n",
      "            for x in sorted(thisdata, key=lambda y: (y[2], y[1], y[0], y[6], y[7], y[8])):\n",
      "                of.write(\"{}\\n\".format('\\t'.join(x)))\n",
      "            of.close()  \n",
      "\n",
      "for kind in px_:\n",
      "    thisdata = px_[kind]\n",
      "    sys.stderr.write('{:>7} {}-participium-like occurrences marked as {} ({}-based)\\n'.format(\n",
      "        len(thisdata), 'total', 'non-verb, non-proper-noun', kind\n",
      "    ))\n",
      "    of = outfile('ptcx_occs_{}_{}.csv'.format('total', kind))\n",
      "    for x in sorted(thisdata, key=lambda y: (y[2], y[1], y[0], y[6], y[7], y[8])):\n",
      "        of.write(\"{}\\n\".format('\\t'.join(x)))\n",
      "    of.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "      1 hifil-participium-like occurrences marked as nmpr (lex-based)\n",
        "      8 hifil-participium-like occurrences marked as nmpr (wrd-based)\n",
        "     41 hifil-participium-like occurrences marked as subs (lex-based)\n",
        "     56 hifil-participium-like occurrences marked as subs (wrd-based)\n",
        "      1 nifal-participium-like occurrences marked as piel.perf (wrd-based)\n",
        "      1 nifal-participium-like occurrences marked as nit.perf (wrd-based)\n",
        "     56 nifal-participium-like occurrences marked as qal.impf (wrd-based)\n",
        "     52 nifal-participium-like occurrences marked as qal.perf (wrd-based)\n",
        "     32 nifal-participium-like occurrences marked as nmpr (lex-based)\n",
        "     50 nifal-participium-like occurrences marked as nmpr (wrd-based)\n",
        "      3 nifal-participium-like occurrences marked as hit.impf (wrd-based)\n",
        "      3 nifal-participium-like occurrences marked as qal.infc (wrd-based)\n",
        "      1 nifal-participium-like occurrences marked as subs (lex-based)\n",
        "    150 nifal-participium-like occurrences marked as subs (wrd-based)\n",
        "    257 nifal-participium-like occurrences marked as nif.perf (wrd-based)\n",
        "      4 nifal-participium-like occurrences marked as prps (lex-based)\n",
        "      1 nifal-participium-like occurrences marked as qal.impv (wrd-based)\n",
        "     12 piel-participium-like occurrences marked as subs (wrd-based)\n",
        "      2 qal1-participium-like occurrences marked as hit.wayq (lex-based)\n",
        "      3 qal1-participium-like occurrences marked as piel.infc (lex-based)\n",
        "      3 qal1-participium-like occurrences marked as piel.infc (wrd-based)\n",
        "      1 qal1-participium-like occurrences marked as hif.infa (wrd-based)\n",
        "     22 qal1-participium-like occurrences marked as qal.wayq (wrd-based)\n",
        "     44 qal1-participium-like occurrences marked as nmpr (lex-based)\n",
        "     55 qal1-participium-like occurrences marked as nmpr (wrd-based)\n",
        "      1 qal1-participium-like occurrences marked as adjv (lex-based)\n",
        "      2 qal1-participium-like occurrences marked as adjv (wrd-based)\n",
        "      1 qal1-participium-like occurrences marked as prep (wrd-based)\n",
        "      2 qal1-participium-like occurrences marked as piel.perf (lex-based)\n",
        "      3 qal1-participium-like occurrences marked as piel.perf (wrd-based)\n",
        "      9 qal1-participium-like occurrences marked as qal.impf (wrd-based)\n",
        "      8 qal1-participium-like occurrences marked as piel.impf (lex-based)\n",
        "      5 qal1-participium-like occurrences marked as hif.perf (wrd-based)\n",
        "     14 qal1-participium-like occurrences marked as hif.impf (wrd-based)\n",
        "     57 qal1-participium-like occurrences marked as subs (lex-based)\n",
        "    162 qal1-participium-like occurrences marked as subs (wrd-based)\n",
        "      2 qal1-participium-like occurrences marked as piel.wayq (lex-based)\n",
        "      1 qal1-participium-like occurrences marked as hif.impv (wrd-based)\n",
        "      3 qal1-participium-like occurrences marked as qal.impv (wrd-based)\n",
        "      1 qal2-participium-like occurrences marked as peal.perf (wrd-based)\n",
        "    257 qal2-participium-like occurrences marked as adjv (lex-based)\n",
        "    356 qal2-participium-like occurrences marked as adjv (wrd-based)\n",
        "      4 qal2-participium-like occurrences marked as nif.impv (lex-based)\n",
        "   2781 qal2-participium-like occurrences marked as nmpr (lex-based)\n",
        "    218 qal2-participium-like occurrences marked as nmpr (wrd-based)\n",
        "    109 qal2-participium-like occurrences marked as prep (lex-based)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    113 qal2-participium-like occurrences marked as prep (wrd-based)\n",
        "    119 qal2-participium-like occurrences marked as nif.impf (lex-based)\n",
        "     25 qal2-participium-like occurrences marked as hif.infc (wrd-based)\n",
        "     22 qal2-participium-like occurrences marked as piel.impf (lex-based)\n",
        "    205 qal2-participium-like occurrences marked as advb (lex-based)\n",
        "    205 qal2-participium-like occurrences marked as advb (wrd-based)\n",
        "      9 qal2-participium-like occurrences marked as nif.wayq (lex-based)\n",
        "     15 qal2-participium-like occurrences marked as nif.infc (lex-based)\n",
        "      2 qal2-participium-like occurrences marked as nif.infc (wrd-based)\n",
        "      1 qal2-participium-like occurrences marked as piel.impv (lex-based)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "      4 qal2-participium-like occurrences marked as piel.impv (wrd-based)\n",
        "      8 qal2-participium-like occurrences marked as nif.perf (wrd-based)\n",
        "      1 qal2-participium-like occurrences marked as pael.impf (lex-based)\n",
        "      3 qal2-participium-like occurrences marked as qal.impv (wrd-based)\n",
        "    273 qal2-participium-like occurrences marked as subs (lex-based)\n",
        "    937 qal2-participium-like occurrences marked as subs (wrd-based)\n",
        "     48 qal2-participium-like occurrences marked as intj (lex-based)\n",
        "     48 qal2-participium-like occurrences marked as intj (wrd-based)\n",
        "     32 qal2-participium-like occurrences marked as qal.impf (wrd-based)\n",
        "     38 qal2-participium-like occurrences marked as hif.infa (wrd-based)\n",
        "      2 qal2-participium-like occurrences marked as hif.wayq (wrd-based)\n",
        "      1 qal2-participium-like occurrences marked as haf.impf (wrd-based)\n",
        "      7 qal2-participium-like occurrences marked as conj (lex-based)\n",
        "      7 qal2-participium-like occurrences marked as conj (wrd-based)\n",
        "     34 qal2-participium-like occurrences marked as piel.infc (lex-based)\n",
        "     47 qal2-participium-like occurrences marked as piel.infc (wrd-based)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "      3 qal2-participium-like occurrences marked as piel.infa (lex-based)\n",
        "      8 qal2-participium-like occurrences marked as piel.infa (wrd-based)\n",
        "    249 qal2-participium-like occurrences marked as qal.perf (lex-based)\n",
        "    259 qal2-participium-like occurrences marked as qal.perf (wrd-based)\n",
        "     43 qal2-participium-like occurrences marked as hif.impf (wrd-based)\n",
        "     16 qal2-participium-like occurrences marked as piel.wayq (lex-based)\n",
        "     69 qal2-participium-like occurrences marked as hif.impv (wrd-based)\n",
        "    157 qal3-participium-like occurrences marked as subs (lex-based)\n",
        "   1660 qal3-participium-like occurrences marked as subs (wrd-based)\n",
        "     82 qal3-participium-like occurrences marked as adjv (lex-based)\n",
        "    379 qal3-participium-like occurrences marked as adjv (wrd-based)\n",
        "      8 qal3-participium-like occurrences marked as qal.wayq (wrd-based)\n",
        "     99 qal3-participium-like occurrences marked as nmpr (lex-based)\n",
        "    304 qal3-participium-like occurrences marked as nmpr (wrd-based)\n",
        "     19 qal3-participium-like occurrences marked as prep (lex-based)\n",
        "     83 qal3-participium-like occurrences marked as prep (wrd-based)\n",
        "      6 qal3-participium-like occurrences marked as piel.infc (wrd-based)\n",
        "    405 qal3-participium-like occurrences marked as qal.impf (wrd-based)\n",
        "    359 qal3-participium-like occurrences marked as prps (wrd-based)\n",
        "      1 qal3-participium-like occurrences marked as qal.infc (wrd-based)\n",
        "      4 qal3-participium-like occurrences marked as nif.infc (wrd-based)\n",
        "    162 qal3-participium-like occurrences marked as qal.infa (lex-based)\n",
        "    364 qal3-participium-like occurrences marked as qal.infa (wrd-based)\n",
        "     12 qal3-participium-like occurrences marked as qal.perf (lex-based)\n",
        "     33 qal3-participium-like occurrences marked as qal.perf (wrd-based)\n",
        "     37 qal3-participium-like occurrences marked as nif.perf (wrd-based)\n",
        "      5 qal3-participium-like occurrences marked as nif.infa (lex-based)\n",
        "      2 qal3-participium-like occurrences marked as nif.infa (wrd-based)\n",
        "      1 qal3-participium-like occurrences marked as pual.ptcp (wrd-based)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "   1261 total-participium-like occurrences marked as non-verb, non-proper-noun (lex-based)\n",
        "   4530 total-participium-like occurrences marked as non-verb, non-proper-noun (wrd-based)\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Check special cases"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "RoZeN (Judges 5:3, Jes 40:23, Hab 1:10, Ps 2:2, Prov 8:15, Prov 31:4)\n",
      "\n",
      "KoReM (2Kon 25:12, Jes 61:5, Joel 1:11, 2Chr 26:10)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search_pats = {\n",
      "    'RZN': re.compile('.*?R.*?Z.*?[Nn]'),\n",
      "    'KRM': re.compile('.*?K.*?R.*?[Mm]'),\n",
      "    'KHN': re.compile('.*?K.*?H.*?N'),\n",
      "    'JGB': re.compile('.*?J.*?G.*?B'),\n",
      "    'NQD': re.compile('.*?N.*?Q.*?D'),\n",
      "}\n",
      "cur_book = None\n",
      "cur_chapter = None\n",
      "cur_verse = None\n",
      "found = []\n",
      "for (gword, glex, lex, psp, vs, vt, book, chapter, verse) in gword_occs:\n",
      "    for pat in search_pats:\n",
      "        if search_pats[pat].search(lex) != None or search_pats[pat].search(glex) != None or search_pats[pat].search(gword) != None:\n",
      "            found.append((gword, glex, lex, psp, vs, vt, book, chapter, verse))\n",
      "\n",
      "of = outfile('specials.csv')\n",
      "for x in sorted(found, key=lambda y: (y[2], y[1], y[0], y[6], y[7], y[8])):\n",
      "    of.write(\"{}\\n\".format('\\t'.join(x)))\n",
      "of.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}