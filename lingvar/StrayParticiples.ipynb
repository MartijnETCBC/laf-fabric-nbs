{
 "metadata": {
  "name": "",
  "signature": "sha256:13bb526be4f8bc6d585247a34b37d243e1edc6ee92323852c3d7b3920e79bf55"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"right\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
      "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"right\"src=\"images/etcbc4easy-small.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Participle: data collection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Hebrew participle, active and passive, is the object of study in this notebook."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Hebrew participle is seen to function in a nominal way, as well as in a verbal way. \n",
      "Sometimes the participle even functions as a finite verb.\n",
      "\n",
      "There are indications that the usage of participles in classical Hebrew indicates a shift in syntactic patterns, either due to temporal evolution or due to geographical distribution.\n",
      "\n",
      "In order to look for the syntactic variation that is centered around the participle, we first have to collect the data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Desiderata"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we are looking for participle like forms that have not been marked as participles in the ETCBC4 database."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Starting up"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "import re\n",
      "from laf.fabric import LafFabric\n",
      "from etcbc.preprocess import prepare\n",
      "fabric = LafFabric()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.4.1\n",
        "http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fabric.load('etcbc4', '--', 'participle', {\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": ('''\n",
      "        otype\n",
      "        book chapter verse label\n",
      "        g_word g_word_utf8 lex_utf8 g_lex\n",
      "        sp\n",
      "    ''','''\n",
      "    '''),\n",
      "    \"primary\": False,\n",
      "})\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: USING DATA COMPILED AT: 2014-07-23T09-31-37\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s INFO: DATA LOADED FROM SOURCE etcbc4 AND ANNOX -- FOR TASK participle AT 2014-08-28T15-08-54\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Get all verb forms with their relevant properties"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We collect a list with all verb occurrences and store their lexeme, verbal stem, verbal tense and the current book.\n",
      "\n",
      "At the same time we also collect a list of all non-verb words and store their lexeme and part-of-speech."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_book = None\n",
      "cur_chapter = None\n",
      "cur_verse = None\n",
      "glexemes = collections.defaultdict(lambda: set())\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'book':\n",
      "        cur_book = F.book.v(n)\n",
      "    elif otype == 'chapter': cur_chapter = F.chapter.v(n)\n",
      "    elif otype == 'verse': cur_verse = F.verse.v(n)\n",
      "    elif otype == 'word': \n",
      "        psp = F.sp.v(n)\n",
      "        glex = F.g_lex.v(n)\n",
      "        gword = F.g_word_utf8.v(n)\n",
      "        glexemes[glex].add(psp)\n",
      "\n",
      "of = outfile('glexemes.csv')\n",
      "for x in sorted(glexemes):\n",
      "    of.write(\"{}\\t{}\\n\".format(x, '\\t'.join(sorted(glexemes[x]))))\n",
      "of.close()\n",
      "\n",
      "sys.stderr.write('{:>7} glexemes\\n'.format(len(glexemes)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  21159 glexemes\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fetch participium-like lexemes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Precise search for most participle like patterns, following the paradigm tables from [Blakley](http://blakleycreative.com/jtb/HebrewGrammar.htm): [strong verb](http://blakleycreative.com/jtb/Text/Paradigms_StrongVerbConsolidation.pdf) and/or Lettinga"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HC = '[>BGDHWZXVJKLMNS<PYQRFCTkmnpy]'\n",
      "ptc_pats = {\n",
      "    'qal1': {\n",
      "        'ms': re.compile(r'{HC}O{HC};{HC}$'.format(HC=HC)),\n",
      "        'mpa': re.compile(r'{HC}O{HC}:{HC}IJ[Mm]$'.format(HC=HC)),\n",
      "        'mpc': re.compile(r'{HC}O{HC}:{HC}EJ$'.format(HC=HC)),\n",
      "        'fs1': re.compile(r'{HC}O{HC}E{HC}ET$'.format(HC=HC)),\n",
      "        'fs2': re.compile(r'{HC}O{HC};{HC}@H$'.format(HC=HC)),\n",
      "        'fs3': re.compile(r'{HC}O{HC}:{HC}@H$'.format(HC=HC)),\n",
      "        'fp': re.compile(r'{HC}O{HC}:{HC}OWT$'.format(HC=HC)),\n",
      "    },\n",
      "    'qal2': {\n",
      "        'ms': re.compile(r'{HC}@{HC};{HC}$'.format(HC=HC)),\n",
      "        'mpa': re.compile(r'{HC}@{HC}:{HC}IJ[Mm]$'.format(HC=HC)),\n",
      "        'mpc': re.compile(r'{HC}@{HC}:{HC}EJ$'.format(HC=HC)),\n",
      "        'fs': re.compile(r'{HC}:{HC};{HC}@H$'.format(HC=HC)),\n",
      "        'fp': re.compile(r'{HC}:{HC}:{HC}OWT$'.format(HC=HC)),\n",
      "    },\n",
      "    'qal3': {\n",
      "        'ms': re.compile(r'{HC}@{HC}O{HC}$'.format(HC=HC)),\n",
      "        'mpa': re.compile(r'{HC}@{HC}:{HC}IJ[Mm]$'.format(HC=HC)),\n",
      "        'mpc': re.compile(r'{HC}@{HC}:{HC}EJ$'.format(HC=HC)),\n",
      "        'fs': re.compile(r'{HC}:{HC}O{HC}@H$'.format(HC=HC)),\n",
      "        'fp': re.compile(r'{HC}:{HC}:{HC}OWT$'.format(HC=HC)),\n",
      "    },\n",
      "    'nifal': {\n",
      "        'ms': re.compile(r'N.{HC}:{HC}\\.?@{HC}$'.format(HC=HC)),\n",
      "        'mpa': re.compile(r'N.{HC}:{HC}\\.?:{HC}IJ[Mm]$'.format(HC=HC)),\n",
      "        'mpc': re.compile(r'N.{HC}:{HC}\\.?:{HC}EJ$'.format(HC=HC)),\n",
      "        'fs1': re.compile(r'N.{HC}E{HC}\\.?E{HC}ET$'.format(HC=HC)),\n",
      "        'fs2': re.compile(r'N.{HC}@{HC}\\.?@{HC}H$'.format(HC=HC)),\n",
      "        'fp': re.compile(r'N.{HC}@{HC}\\.?@{HC}OWT$'.format(HC=HC)),\n",
      "    },\n",
      "    'piel': {\n",
      "        'ms': re.compile(r'M:{HC}A{HC}\\.;{HC}$'.format(HC=HC)),\n",
      "        'mpa': re.compile(r'M:{HC}A{HC}\\.:{HC}IJ[Mm]$'.format(HC=HC)),\n",
      "        'mpc': re.compile(r'M:{HC}A{HC}\\.:{HC}EJ$'.format(HC=HC)),\n",
      "        'fs1': re.compile(r'M:{HC}A{HC}\\.E{HC}ET$'.format(HC=HC)),\n",
      "        'fs2': re.compile(r'M:{HC}A{HC}\\.:{HC}H$'.format(HC=HC)),\n",
      "        'fp': re.compile(r'M:{HC}A{HC}\\.:{HC}OWT$'.format(HC=HC)),\n",
      "    },\n",
      "    'hifil': {\n",
      "        'ms': re.compile(r'MA{HC}:{HC}\\.?IJ?{HC}$'.format(HC=HC)),\n",
      "        'mpa': re.compile(r'MA{HC}:{HC}\\.?IJ?{HC}IJ[Mm]$'.format(HC=HC)),\n",
      "        'mpc': re.compile(r'MA{HC}:{HC}\\.?IJ?{HC}EJ$'.format(HC=HC)),\n",
      "        'fs1': re.compile(r'MA{HC}:{HC}\\.E{HC}ET$'.format(HC=HC)),\n",
      "        'fs2': re.compile(r'MA{HC}:{HC}\\.?IJ?{HC}H$'.format(HC=HC)),\n",
      "        'fp': re.compile(r'MA{HC}:{HC}\\.?IJ?{HC}OWT$'.format(HC=HC)),\n",
      "    },\n",
      "    'hitpael': {\n",
      "        'ms': re.compile(r'MIT:{HC}\\.?A{HC}\\.;{HC}$'.format(HC=HC)),\n",
      "        'mpa': re.compile(r'MIT:{HC}\\.?A{HC}\\.:{HC}IJ[Mm]$'.format(HC=HC)),\n",
      "        'mpc': re.compile(r'MIT:{HC}\\.?A{HC}\\.:{HC}EJ$'.format(HC=HC)),\n",
      "        'fs1': re.compile(r'MIT:{HC}\\.?A{HC}\\.E{HC}ET$'.format(HC=HC)),\n",
      "        'fs2': re.compile(r'MIT:{HC}\\.?A{HC}\\.:{HC}H$'.format(HC=HC)),\n",
      "        'fp': re.compile(r'MIT:{HC}\\.?A{HC}\\.:{HC}OWT$'.format(HC=HC)),\n",
      "    },\n",
      "}\n",
      "px_lexemes = collections.defaultdict(lambda: set())\n",
      "for glex in glexemes:\n",
      "    for stem in ptc_pats:\n",
      "        for pat in ptc_pats[stem]:\n",
      "            if ptc_pats[stem][pat].search(glex) != None:\n",
      "                psps = glexemes[glex]\n",
      "                if 'verb' in psps and len(psps) == 1: continue\n",
      "                if 'nmpr' in psps and len(psps) == 1: continue\n",
      "                if 'nmpr' in psps and 'verb' in psps and len(psps) == 2: continue\n",
      "                px_lexemes[stem].add(glex)\n",
      "\n",
      "for stem in sorted(ptc_pats):\n",
      "    data = px_lexemes.get(stem, {})\n",
      "    sys.stderr.write('{:>7} in {}-participium-like lexemes\\n'.format(len(data), stem))\n",
      "    of = outfile('ptcx_lexemes_{}.csv'.format(stem))\n",
      "    for glex in sorted(px_lexemes[stem]):\n",
      "        of.write('{}\\t{}\\n'.format(glex, ','.join(sorted(glexemes[glex]))))\n",
      "    of.close()  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "      7 in hifil-participium-like lexemes\n",
        "      0 in hitpael-participium-like lexemes\n",
        "      3 in nifal-participium-like lexemes\n",
        "      0 in piel-participium-like lexemes\n",
        "     17 in qal1-participium-like lexemes\n",
        "     65 in qal2-participium-like lexemes\n",
        "     33 in qal3-participium-like lexemes\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Known cases"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are a few known cases. Do we find them? No. \n",
      "Because the participium-like vowel pattern is not testified in the text.\n",
      "Some dictionaries deduce a participium here."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "RoZeN (Judges 5:3, Jes 40:23, Hab 1:10, Ps 2:2, Prov 8:15, Prov 31:4)\n",
      "KoReM (2Kon 25:12, Jes 61:5, Joel 1:11, 2Chr 26:10)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search_pats = {\n",
      "    'RZN': re.compile('.*?R.*?Z.*?[Nn]'),\n",
      "    'KRM': re.compile('.*?K.*?R.*?[Mm]'),\n",
      "}\n",
      "cur_book = None\n",
      "cur_chapter = None\n",
      "cur_verse = None\n",
      "found = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(lambda: [])))\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'book':\n",
      "        cur_book = F.book.v(n)\n",
      "    elif otype == 'chapter': cur_chapter = F.chapter.v(n)\n",
      "    elif otype == 'verse': cur_verse = F.verse.v(n)\n",
      "    elif otype == 'word':\n",
      "        glex = F.g_lex.v(n)\n",
      "        gword = F.g_word.v(n)\n",
      "        for pat in search_pats:\n",
      "            if search_pats[pat].search(glex) != None or search_pats[pat].search(gword) != None:\n",
      "                found[pat][glex][gword].append((cur_book, cur_chapter, cur_verse))\n",
      "\n",
      "of = outfile('specials.csv')\n",
      "for pat in sorted(search_pats):\n",
      "    sys.stderr.write('{}: {} found\\n'.format(pat, len(found[pat]) if pat in found else 0))\n",
      "    if pat in found:\n",
      "        for glex in sorted(found[pat]):\n",
      "            for gword in sorted(found[pat][glex]):\n",
      "                of.write('{}\\t{:<10}\\t{:<20}\\t{}\\n'.format(pat, glex, gword, ', '.join('{} {}:{}'.format(*x) for x in found[pat][glex][gword])))\n",
      "of.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "KRM: 98 found\n",
        "RZN: 13 found\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}