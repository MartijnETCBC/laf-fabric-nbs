{
 "metadata": {
  "name": "",
  "signature": "sha256:27acc0160fb7738018d288f84098104928649830b81f8f3d9d12a7655fe36998"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"right\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
      "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"right\"src=\"images/etcbc4easy-small.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Complement Collection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook collects the complements to the verb in each clause.\n",
      "\n",
      "The purpose is to create a spreadsheet in which each row corresponds to a clause.\n",
      "The first column is filled with the lexeme of the verb phrase of the clause, the next columns correspond to the various complements of the verb phrase in that clause."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "\n",
      "import laf\n",
      "from laf.fabric import LafFabric\n",
      "from etcbc.preprocess import prepare\n",
      "from etcbc.lib import Transcription, monad_set\n",
      "from etcbc.trees import Tree\n",
      "\n",
      "fabric = LafFabric()\n",
      "tr = Transcription()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.4.1\n",
        "http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s END\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API = fabric.load('etcbc4', '--', 'clausecomplements', {\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": ('''\n",
      "        oid otype monads\n",
      "        book chapter verse\n",
      "        sp lex function g_word trailer_utf8\n",
      "    ''','''\n",
      "    '''),\n",
      "    \"prepare\": prepare,\n",
      "}, verbose='NORMAL')\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: USING DATA COMPILED AT: 2014-07-23T09-31-37\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.08s LOGFILE=/Users/dirk/laf-fabric-output/etcbc4/clausecomplements/__log__clausecomplements.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.84s INFO: DATA LOADED FROM SOURCE etcbc4 AND ANNOX -- FOR TASK clausecomplements AT 2014-09-17T10-14-11\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We construct the trees for each clause, and we only put clause, phrase and word nodes in the trees.\n",
      "After the construction, each clause has phrase children, which are all phrases that are contained (as monad set) in the clause, and likewise every phrase has word children, which are all words contained in that phrase.\n",
      "\n",
      "We do not have phrases inside phrases. All phrases occur at the same level, but they are ordered by the canonical ordering: the phrase that contains the first monad that is not contained in the other phrase comes first."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree_types = ('clause', 'phrase', 'word')\n",
      "(root_type, leaf_type, clause_type) = (tree_types[0], tree_types[-1], 'clause')\n",
      "\n",
      "tree = Tree(API, otypes=tree_types, \n",
      "    clause_type=clause_type,\n",
      "    ccr_feature=None,\n",
      "    pt_feature=None,\n",
      "    pos_feature='sp',\n",
      "    mother_feature =None,\n",
      ")\n",
      "results = tree.relations()\n",
      "parent = results['eparent']\n",
      "children = results['echildren']\n",
      "msg(\"Ready for processing\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API with EXTRAs: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: USING DATA COMPILED AT: 2014-07-23T09-31-37\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.02s INFO: DATA LOADED FROM SOURCE etcbc4 AND ANNOX -- FOR TASK clausecomplements AT 2014-09-17T10-14-18\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s Start computing parent and children relations for objects of type clause, phrase, word\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.18s 100000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.13s 200000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.29s 300000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.35s 400000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    10s 500000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    12s 600000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    14s 700000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    16s 769197 nodes: 681219 have parents and 342642 have children\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    16s Ready for processing\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make a passage index for the clauses"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_book = None\n",
      "cur_chapter = None\n",
      "cur_verse = None\n",
      "clause_passage = {}\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'book': cur_book = F.book.v(n)\n",
      "    elif otype == 'chapter': cur_chapter = F.chapter.v(n)\n",
      "    elif otype == 'verse': cur_verse = F.verse.v(n)\n",
      "    elif otype == 'clause': clause_passage[n] = (cur_book, cur_chapter, cur_verse)\n",
      "nclauses = len(clause_passage)\n",
      "clause_order = sorted(clause_passage)\n",
      "msg(\"Passage index created for {} clauses\".format(nclauses))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    31s Passage index created for 87978 clauses\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make an index of the transcriptions of clauses and phrases"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "node_transcr = {}\n",
      "\n",
      "for clause in clause_order:\n",
      "    clause_transcr = ''\n",
      "    for phrase in children[clause]:\n",
      "        phrase_transcr = ''\n",
      "        for word in children[phrase]:\n",
      "            word_transcr = F.g_word.v(word) + tr.from_hebrew(F.trailer_utf8.v(word)).replace('_',' ').replace('\\n',' ')\n",
      "            node_transcr[word] = word_transcr.rstrip(' ')\n",
      "            phrase_transcr += word_transcr\n",
      "            clause_transcr += word_transcr\n",
      "        node_transcr[phrase] = phrase_transcr.rstrip(' ')\n",
      "    node_transcr[clause] = clause_transcr.rstrip(' ')\n",
      "msg(\"Transcription index created for {} nodes\".format(len(node_transcr)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    39s Transcription index created for 769197 nodes\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Explore the phrase functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_functions = collections.defaultdict(lambda: 0)\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'phrase':\n",
      "        phrase_functions[F.function.v(n)] += 1\n",
      "for value in sorted(phrase_functions):\n",
      "    print(\"{:<20} {:>6d} x\".format(value, phrase_functions[value]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adju                   8857 x\n",
        "Cmpl                  27949 x\n",
        "Conj                  46291 x\n",
        "EPPr                      4 x\n",
        "ExsS                     14 x\n",
        "Exst                    144 x\n",
        "Frnt                   1026 x\n",
        "IntS                    250 x\n",
        "Intj                   1627 x\n",
        "Loca                   2510 x\n",
        "ModS                     36 x\n",
        "Modi                   3703 x\n",
        "NCoS                    101 x\n",
        "NCop                    609 x\n",
        "Nega                   6058 x\n",
        "Objc                  20816 x\n",
        "PrAd                     84 x\n",
        "PrcS                      8 x\n",
        "PreC                  17765 x\n",
        "PreO                   5514 x\n",
        "PreS                    778 x\n",
        "Pred                  57046 x\n",
        "PtcO                    166 x\n",
        "Ques                   1275 x\n",
        "Rela                   6338 x\n",
        "Subj                  28957 x\n",
        "Supp                    296 x\n",
        "Time                   3551 x\n",
        "Unkn                  11367 x\n",
        "Voct                   1524 x\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pick up the complements(s), and collect the lexemes of the verbs inside the verb phrases."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "comptype_order = (\n",
      "    'predicate',\n",
      "    'subject',\n",
      "    'object',\n",
      "    'complement',\n",
      "    'adjunct',\n",
      "    'situation',\n",
      "    'unclassified',\n",
      ")\n",
      "ct_pred = 0\n",
      "ct_subj = 1\n",
      "ct_obj = 2\n",
      "ct_compl = 3\n",
      "ct_adj = 4\n",
      "ct_situ = 5\n",
      "ct_rest = 6\n",
      "ct_none = len(comptype_order) - 1\n",
      "\n",
      "comptype = {\n",
      "    'Subj': ct_subj,\n",
      "    'PreS': ct_subj,\n",
      "    'Pred': ct_pred,\n",
      "    'PreO': ct_pred,\n",
      "    'PreS': ct_pred,\n",
      "    'PtcO': ct_pred,\n",
      "    'Objc': ct_obj,\n",
      "    'PreO': ct_obj,\n",
      "    'PtcO': ct_obj,\n",
      "    'Cmpl': ct_compl,\n",
      "    'PreC': ct_compl,\n",
      "    'Adju': ct_adj,\n",
      "    'PrAd': ct_adj,\n",
      "    'Loca': ct_situ,\n",
      "    'Time': ct_situ,\n",
      "    'Modi': ct_rest,\n",
      "    'Supp': ct_rest,\n",
      "}\n",
      "\n",
      "vp_lexemes = {}\n",
      "clause_phrases = collections.defaultdict(lambda: collections.defaultdict(lambda: []))\n",
      "\n",
      "for clause in clause_order:\n",
      "    phrases = children[clause]\n",
      "    verbs = []\n",
      "    for p in phrases:\n",
      "        cpt = comptype.get(F.function.v(p), ct_none)\n",
      "        clause_phrases[cpt][clause].append(p)\n",
      "        if cpt == ct_pred:\n",
      "            for word in children[p]:\n",
      "                if F.sp.v(word) == 'verb':\n",
      "                    verbs.append(F.lex.v(word).rstrip('[/='))\n",
      "    vp_lexemes[clause] = ' '.join(verbs)\n",
      "\n",
      "\n",
      "phrase_distribution = collections.defaultdict(lambda: collections.defaultdict(lambda:0))\n",
      "for ctp in sorted(clause_phrases):\n",
      "    for clause in clause_phrases[ctp]:\n",
      "        phrase_distribution[ctp][len(clause_phrases[ctp][clause])] += 1\n",
      "    \n",
      "msg(\"{} clauses\".format(\n",
      "    nclauses, \n",
      "))\n",
      "\n",
      "maxnphrases = {}\n",
      "for ctp in sorted(phrase_distribution):\n",
      "    for n in sorted(phrase_distribution[ctp]):\n",
      "        maxnphrases[ctp] = n\n",
      "        print(\"{:>5} clauses with {:>2} {}{}\".format(\n",
      "            phrase_distribution[ctp][n], n, comptype_order[ctp], 's' if n != 1 else ''\n",
      "        ))\n",
      "for ctp in sorted(maxnphrases):\n",
      "    print(\"There are at most {} {}s in a clause\".format(maxnphrases[ctp], comptype_order[ctp]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "51m 18s 87978 clauses\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "57824 clauses with  1 predicate\n",
        "28957 clauses with  1 subject\n",
        "24446 clauses with  1 object\n",
        "  990 clauses with  2 objects\n",
        "   15 clauses with  3 objects\n",
        "    5 clauses with  4 objects\n",
        "    1 clauses with  5 objects\n",
        "37168 clauses with  1 complement\n",
        " 4180 clauses with  2 complements\n",
        "   59 clauses with  3 complements\n",
        "    1 clauses with  4 complements\n",
        "    1 clauses with  5 complements\n",
        " 7857 clauses with  1 adjunct\n",
        "  451 clauses with  2 adjuncts\n",
        "   54 clauses with  3 adjuncts\n",
        "    5 clauses with  4 adjuncts\n",
        " 5352 clauses with  1 situation\n",
        "  286 clauses with  2 situations\n",
        "   40 clauses with  3 situations\n",
        "    3 clauses with  4 situations\n",
        "    1 clauses with  5 situations\n",
        "49632 clauses with  1 unclassified\n",
        " 9929 clauses with  2 unclassifieds\n",
        " 2342 clauses with  3 unclassifieds\n",
        "  612 clauses with  4 unclassifieds\n",
        "  192 clauses with  5 unclassifieds\n",
        "   66 clauses with  6 unclassifieds\n",
        "   29 clauses with  7 unclassifieds\n",
        "   10 clauses with  8 unclassifieds\n",
        "    5 clauses with  9 unclassifieds\n",
        "    1 clauses with 10 unclassifieds\n",
        "    1 clauses with 13 unclassifieds\n",
        "There are at most 1 predicates in a clause\n",
        "There are at most 1 subjects in a clause\n",
        "There are at most 5 objects in a clause\n",
        "There are at most 5 complements in a clause\n",
        "There are at most 4 adjuncts in a clause\n",
        "There are at most 5 situations in a clause\n",
        "There are at most 13 unclassifieds in a clause\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Print complete data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "of = outfile('clauses.csv')\n",
      "header = 'passage\\tverblex\\t'\n",
      "for cpt in range(len(comptype_order) - 1):\n",
      "    header += '#{}\\t'.format(comptype_order[cpt])\n",
      "for cpt in range(len(comptype_order) - 1):\n",
      "    for i in range(maxnphrases[cpt]):\n",
      "        header += '{}{}\\t'.format(comptype_order[cpt], i + 1)\n",
      "header += 'clause\\n'\n",
      "of.write(header)\n",
      "\n",
      "for clause in clause_order:\n",
      "    passage = '{} {}:{}'.format(*clause_passage[clause])\n",
      "    verb_lex = vp_lexemes[clause]\n",
      "    complements = []\n",
      "    stats = []\n",
      "    for cpt in range(len(comptype_order) - 1):\n",
      "        phrases = clause_phrases[cpt][clause]\n",
      "        nphrases = len(phrases)\n",
      "        stats.append(str(nphrases))\n",
      "        for i in range(maxnphrases[cpt]):\n",
      "            complements.append(node_transcr[phrases[i]] if i < nphrases else '')\n",
      "\n",
      "    of.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(\n",
      "        passage, \n",
      "        verb_lex, \n",
      "        '\\t'.join(stats),\n",
      "        '\\t'.join(complements),\n",
      "        node_transcr[clause],\n",
      "    ))\n",
      "of.close()\n",
      "msg(\"{} clauses\".format(nclauses))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "51m 27s 87978 clauses\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}