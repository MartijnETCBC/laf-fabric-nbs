{
 "metadata": {
  "name": "",
  "signature": "sha256:90857a6afd6640564b1f2bf285fc41fcd449c1aa38fbf3fc761e378e548fa9ce"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"right\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
      "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"right\"src=\"images/etcbc4easy-small.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Complement Collection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook collects the complements to the verb in each clause.\n",
      "\n",
      "The purpose is to create a spreadsheet in which each row corresponds to a clause.\n",
      "The first column is filled with the lexeme of the verb phrase of the clause, the next columns correspond to the various complements of the verb phrase in that clause."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "\n",
      "import laf\n",
      "from laf.fabric import LafFabric\n",
      "from etcbc.preprocess import prepare\n",
      "from etcbc.lib import Transcription, monad_set\n",
      "from etcbc.trees import Tree\n",
      "\n",
      "fabric = LafFabric()\n",
      "tr = Transcription()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.4.1\n",
        "http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API = fabric.load('etcbc4', '--', 'clausecomplements', {\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": ('''\n",
      "        oid otype monads\n",
      "        book chapter verse\n",
      "        sp lex function g_word trailer_utf8\n",
      "    ''','''\n",
      "    '''),\n",
      "    \"prepare\": prepare,\n",
      "}, verbose='NORMAL')\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: USING DATA COMPILED AT: 2014-07-23T09-31-37\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.77s LOGFILE=/Users/dirk/laf-fabric-output/etcbc4/clausecomplements/__log__clausecomplements.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.29s INFO: DATA LOADED FROM SOURCE etcbc4 AND ANNOX -- FOR TASK clausecomplements AT 2014-09-16T15-27-39\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We construct the trees for each clause, and we only put clause, phrase and word nodes in the trees.\n",
      "After the construction, each clause has phrase children, which are all phrases that are contained (as monad set) in the clause, and likewise every phrase has word children, which are all words contained in that phrase.\n",
      "\n",
      "We do not have phrases inside phrases. All phrases occur at the same level, but they are ordered by the canonical ordering: the phrase that contains the first monad that is not contained in the other phrase comes first."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree_types = ('clause', 'phrase', 'word')\n",
      "(root_type, leaf_type, clause_type) = (tree_types[0], tree_types[-1], 'clause')\n",
      "\n",
      "tree = Tree(API, otypes=tree_types, \n",
      "    clause_type=clause_type,\n",
      "    ccr_feature=None,\n",
      "    pt_feature=None,\n",
      "    pos_feature='sp',\n",
      "    mother_feature =None,\n",
      ")\n",
      "results = tree.relations()\n",
      "parent = results['eparent']\n",
      "children = results['echildren']\n",
      "msg(\"Ready for processing\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API with EXTRAs: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: USING DATA COMPILED AT: 2014-07-23T09-31-37\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.73s INFO: DATA LOADED FROM SOURCE etcbc4 AND ANNOX -- FOR TASK clausecomplements AT 2014-09-16T15-27-42\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s Start computing parent and children relations for objects of type clause, phrase, word\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.31s 100000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.65s 200000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.97s 300000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.29s 400000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.84s 500000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.19s 600000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.54s 700000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    10s 769197 nodes: 681219 have parents and 342642 have children\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    10s Ready for processing\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make a passage index for the clauses"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_book = None\n",
      "cur_chapter = None\n",
      "cur_verse = None\n",
      "clause_passage = {}\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'book': cur_book = F.book.v(n)\n",
      "    elif otype == 'chapter': cur_chapter = F.chapter.v(n)\n",
      "    elif otype == 'verse': cur_verse = F.verse.v(n)\n",
      "    elif otype == 'clause': clause_passage[n] = (cur_book, cur_chapter, cur_verse)\n",
      "nclauses = len(clause_passage)\n",
      "clause_order = sorted(clause_passage)\n",
      "msg(\"Passage index created for {} clauses\".format(nclauses))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 58s Passage index created for 87978 clauses\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make an index of the transcriptions of clauses and phrases"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "node_transcr = {}\n",
      "\n",
      "for clause in clause_order:\n",
      "    clause_transcr = ''\n",
      "    for phrase in children[clause]:\n",
      "        phrase_transcr = ''\n",
      "        for word in children[phrase]:\n",
      "            word_transcr = F.g_word.v(word) + tr.from_hebrew(F.trailer_utf8.v(word)).replace('_',' ').replace('\\n',' ')\n",
      "            node_transcr[word] = word_transcr.rstrip(' ')\n",
      "            phrase_transcr += word_transcr\n",
      "            clause_transcr += word_transcr\n",
      "        node_transcr[phrase] = phrase_transcr.rstrip(' ')\n",
      "    node_transcr[clause] = clause_transcr.rstrip(' ')\n",
      "msg(\"Transcription index created for {} nodes\".format(len(node_transcr)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 05s Transcription index created for 769197 nodes\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Explore the phrase functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_functions = collections.defaultdict(lambda: 0)\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'phrase':\n",
      "        phrase_functions[F.function.v(n)] += 1\n",
      "for value in sorted(phrase_functions):\n",
      "    print(\"{:<20} {:>6d} x\".format(value, phrase_functions[value]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adju                   8857 x\n",
        "Cmpl                  27949 x\n",
        "Conj                  46291 x\n",
        "EPPr                      4 x\n",
        "ExsS                     14 x\n",
        "Exst                    144 x\n",
        "Frnt                   1026 x\n",
        "IntS                    250 x\n",
        "Intj                   1627 x\n",
        "Loca                   2510 x\n",
        "ModS                     36 x\n",
        "Modi                   3703 x\n",
        "NCoS                    101 x\n",
        "NCop                    609 x\n",
        "Nega                   6058 x\n",
        "Objc                  20816 x\n",
        "PrAd                     84 x\n",
        "PrcS                      8 x\n",
        "PreC                  17765 x\n",
        "PreO                   5514 x\n",
        "PreS                    778 x\n",
        "Pred                  57046 x\n",
        "PtcO                    166 x\n",
        "Ques                   1275 x\n",
        "Rela                   6338 x\n",
        "Subj                  28957 x\n",
        "Supp                    296 x\n",
        "Time                   3551 x\n",
        "Unkn                  11367 x\n",
        "Voct                   1524 x\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make an index of lexemes corresponding to the verbs in verb phrases"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pick up the verb phrases."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicates = dict(\n",
      "    Pred = 0,\n",
      "    PreO = 1,\n",
      "    PreS = 2,\n",
      "    PtcO = 3,\n",
      ")\n",
      "\n",
      "vp_lexemes = {}\n",
      "empty_clauses = 0\n",
      "verbless_clauses = 0\n",
      "multverb_clauses = 0\n",
      "clause_verb = collections.defaultdict(lambda: [])\n",
      "\n",
      "for clause in clause_order:\n",
      "    phrases = children[clause]\n",
      "    if len(phrases) == 0:\n",
      "        empty_clauses += 1\n",
      "        next\n",
      "    verb_phrases = [p for p in phrases if F.function.v(p) in predicates]\n",
      "    if len(verb_phrases) == 0:\n",
      "        verbless_clauses += 1\n",
      "        next\n",
      "    if len(verb_phrases) > 1:\n",
      "        multverb_clauses += 1\n",
      "    clause_verb[clause] = verb_phrases\n",
      "    verbs = []\n",
      "    for vp in verb_phrases:\n",
      "        for word in children[vp]:\n",
      "            if F.sp.v(word) == 'verb':\n",
      "                verbs.append(F.lex.v(word).rstrip('[/='))\n",
      "    vp_lexemes[clause] = ' '.join(verbs)\n",
      "\n",
      "verb_distribution = collections.defaultdict(lambda: 0)\n",
      "for clause in clause_order:\n",
      "    verb_distribution[len(clause_verb[clause])] += 1\n",
      "    \n",
      "msg(\"{} clauses of which {} empty, {} verbless, {} with multiple verbs, {} with a unique verb\".format(\n",
      "    nclauses, empty_clauses, verbless_clauses, multverb_clauses,\n",
      "    nclauses - empty_clauses - verbless_clauses - multverb_clauses,\n",
      "))\n",
      "\n",
      "for n in sorted(verb_distribution):\n",
      "    print(\"{:>5} clauses with {:>2} verb{}\".format(verb_distribution[n], n, 's' if n != 1 else ''))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 11s 87978 clauses of which 0 empty, 24475 verbless, 1 with multiple verbs, 63502 with a unique verb\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "24475 clauses with  0 verbs\n",
        "63502 clauses with  1 verb\n",
        "    1 clauses with  2 verbs\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Show the multiple verb clauses"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "of = outfile('multiple_verb_clauses.csv')\n",
      "nv = 0\n",
      "for clause in clause_order:\n",
      "    verb_phrases = clause_verb[clause]\n",
      "    if len(verb_phrases) > 1:\n",
      "        nv += 1\n",
      "        (bk, ch, vs) = clause_passage[clause]\n",
      "        verb_texts = (node_transcr[vp] for vp in verb_phrases)\n",
      "        of.write('{} {}:{}\\t{}\\t{}\\n'.format(\n",
      "            bk, ch, vs, '\\t'.join(verb_texts), node_transcr[clause]\n",
      "        ))\n",
      "of.close()\n",
      "msg(\"{} multiple verb clauses written\".format(nv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 13s 1 multiple verb clauses written\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Show the verb single clauses"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "of = outfile('single_verb_clauses.csv')\n",
      "sclause_order = [c for c in clause_order if len(clause_verb[c]) == 1]\n",
      "nsclauses = len(sclause_order)\n",
      "for clause in sclause_order:\n",
      "    verb_phrases = clause_verb[clause]\n",
      "    (bk, ch, vs) = clause_passage[clause]\n",
      "    verb_texts = (node_transcr[vp] for vp in verb_phrases)\n",
      "    of.write('{} {}:{}\\t{}\\t{}\\n'.format(\n",
      "        bk, ch, vs, '\\t'.join(verb_texts), node_transcr[clause]\n",
      "    ))\n",
      "of.close()\n",
      "msg(\"{} single verb clauses written\".format(nsclauses))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 18s 63502 single verb clauses written\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pickup the objects"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clause_object = collections.defaultdict(lambda: [])\n",
      "objects = dict(\n",
      "    Objc = 0,\n",
      "    PreO = 1,\n",
      "    PtcO = 2,\n",
      ")\n",
      "\n",
      "for clause in sclause_order:\n",
      "    phrases = children[clause]\n",
      "    object_phrases = [p for p in phrases if F.function.v(p) in objects]\n",
      "    clause_object[clause] = object_phrases\n",
      "\n",
      "object_distribution = collections.defaultdict(lambda: 0)\n",
      "for clause in sclause_order:\n",
      "    object_distribution[len(clause_object[clause])] += 1\n",
      "    \n",
      "msg(\"{} single verb clauses\".format(\n",
      "    nsclauses, \n",
      "))\n",
      "\n",
      "maxnobjects = 0\n",
      "for n in sorted(object_distribution):\n",
      "    maxnobjects = n\n",
      "    print(\"{:>5} clauses with {:>2} object{}\".format(object_distribution[n], n, 's' if n != 1 else ''))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 22s 63502 single verb clauses\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "40498 clauses with  0 objects\n",
        "22080 clauses with  1 object\n",
        "  904 clauses with  2 objects\n",
        "   15 clauses with  3 objects\n",
        "    4 clauses with  4 objects\n",
        "    1 clauses with  5 objects\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Print complete data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "of = outfile('verb_complements.csv')\n",
      "of.write(\"passage\\tverb_lex\\tvp\\t{}\\tclause\\n\".format('\\t'.join('obj{}'.format(i+1) for i in range(maxnobjects))))\n",
      "for clause in sclause_order:\n",
      "    verb = clause_verb[clause][0]\n",
      "    objects = clause_object[clause]\n",
      "    objects_gen = (objects[i] if i < len(objects) else None for i in range(maxnobjects))\n",
      "    (bk, ch, vs) = clause_passage[clause]\n",
      "    verb_text = node_transcr[verb]\n",
      "    verb_lex = vp_lexemes[clause]\n",
      "    object_texts = [node_transcr[ob] if ob != None else '' for ob in objects_gen]\n",
      "\n",
      "    of.write('{} {}:{}\\t{}\\t{}\\t{}\\t{}\\n'.format(\n",
      "        bk, ch, vs, verb_lex, verb_text, '\\t'.join(object_texts), node_transcr[clause]\n",
      "    ))\n",
      "of.close()\n",
      "msg(\"{} verbs with complements written\".format(nsclauses))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 26s 63502 verbs with complements written\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}