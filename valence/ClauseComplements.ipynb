{
 "metadata": {
  "name": "",
  "signature": "sha256:bd6424d58acffcc5019b8a7af5780854d825616a039e554fedc82e38f17c1ecb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"right\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
      "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"right\"src=\"images/etcbc4easy-small.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Complement Collection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook collects the complements to the verb in each clause.\n",
      "\n",
      "The purpose is to create a spreadsheet in which each row corresponds to a clause.\n",
      "The first column is filled with the lexeme of the verb phrase of the clause, the next columns correspond to the various complements of the verb phrase in that clause.\n",
      "\n",
      "<img align=\"right\"src=\"images/Complements.png\"/></a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Firing up the engines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "\n",
      "import laf\n",
      "from laf.fabric import LafFabric\n",
      "from etcbc.preprocess import prepare\n",
      "from etcbc.lib import Transcription, monad_set\n",
      "from etcbc.trees import Tree\n",
      "\n",
      "fabric = LafFabric()\n",
      "tr = Transcription()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.4.1\n",
        "http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API = fabric.load('etcbc4', '--', 'clausecomplements', {\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": ('''\n",
      "        oid otype monads\n",
      "        book chapter verse\n",
      "        sp lex function g_word trailer_utf8\n",
      "    ''','''\n",
      "    '''),\n",
      "    \"prepare\": prepare,\n",
      "}, verbose='NORMAL')\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: USING DATA COMPILED AT: 2014-07-23T09-31-37\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.24s LOGFILE=/Users/dirk/laf-fabric-output/etcbc4/clausecomplements/__log__clausecomplements.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.79s INFO: DATA LOADED FROM SOURCE etcbc4 AND ANNOX -- FOR TASK clausecomplements AT 2014-09-17T13-00-32\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Tree Construction\n",
      "\n",
      "We construct the trees for each clause, and we only put clause, phrase and word nodes in the trees.\n",
      "After the construction, each clause has phrase children, which are all phrases that are contained (as monad set) in the clause, and likewise every phrase has word children, which are all words contained in that phrase.\n",
      "\n",
      "We do not have phrases inside phrases. All phrases occur at the same level, but they are ordered by the canonical ordering: the phrase that contains the first monad that is not contained in the other phrase comes first."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree_types = ('clause', 'phrase', 'word')\n",
      "(root_type, leaf_type, clause_type) = (tree_types[0], tree_types[-1], 'clause')\n",
      "\n",
      "tree = Tree(API, otypes=tree_types, \n",
      "    clause_type=clause_type,\n",
      "    ccr_feature=None,\n",
      "    pt_feature=None,\n",
      "    pos_feature='sp',\n",
      "    mother_feature =None,\n",
      ")\n",
      "results = tree.relations()\n",
      "parent = results['eparent']\n",
      "children = results['echildren']\n",
      "msg(\"Ready for processing\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API with EXTRAs: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: USING DATA COMPILED AT: 2014-07-23T09-31-37\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.76s INFO: DATA LOADED FROM SOURCE etcbc4 AND ANNOX -- FOR TASK clausecomplements AT 2014-09-17T13-00-34\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s Start computing parent and children relations for objects of type clause, phrase, word\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.69s 100000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.07s 200000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.51s 300000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.90s 400000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.28s 500000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.62s 600000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    10s 700000 nodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s 769197 nodes: 681219 have parents and 342642 have children\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s Ready for processing\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Make a passage index for the clauses"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_book = None\n",
      "cur_chapter = None\n",
      "cur_verse = None\n",
      "clause_passage = {}\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'book': cur_book = F.book.v(n)\n",
      "    elif otype == 'chapter': cur_chapter = F.chapter.v(n)\n",
      "    elif otype == 'verse': cur_verse = F.verse.v(n)\n",
      "    elif otype == 'clause': clause_passage[n] = (cur_book, cur_chapter, cur_verse)\n",
      "nclauses = len(clause_passage)\n",
      "clause_order = sorted(clause_passage)\n",
      "msg(\"Passage index created for {} clauses\".format(nclauses))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    15s Passage index created for 87978 clauses\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Make an index of the transcriptions of clauses and phrases"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "node_transcr = {}\n",
      "\n",
      "for clause in clause_order:\n",
      "    clause_transcr = ''\n",
      "    for phrase in children[clause]:\n",
      "        phrase_transcr = ''\n",
      "        for word in children[phrase]:\n",
      "            word_transcr = F.g_word.v(word) + tr.from_hebrew(F.trailer_utf8.v(word)).replace('_',' ').replace('\\n',' ')\n",
      "            node_transcr[word] = word_transcr.rstrip(' ')\n",
      "            phrase_transcr += word_transcr\n",
      "            clause_transcr += word_transcr\n",
      "        node_transcr[phrase] = phrase_transcr.rstrip(' ')\n",
      "    node_transcr[clause] = clause_transcr.rstrip(' ')\n",
      "msg(\"Transcription index created for {} nodes\".format(len(node_transcr)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    22s Transcription index created for 769197 nodes\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Explore the phrase functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_functions = collections.defaultdict(lambda: 0)\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'phrase':\n",
      "        phrase_functions[F.function.v(n)] += 1\n",
      "for value in sorted(phrase_functions):\n",
      "    print(\"{:<20} {:>6d} x\".format(value, phrase_functions[value]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adju                   8857 x\n",
        "Cmpl                  27949 x\n",
        "Conj                  46291 x\n",
        "EPPr                      4 x\n",
        "ExsS                     14 x\n",
        "Exst                    144 x\n",
        "Frnt                   1026 x\n",
        "IntS                    250 x\n",
        "Intj                   1627 x\n",
        "Loca                   2510 x\n",
        "ModS                     36 x\n",
        "Modi                   3703 x\n",
        "NCoS                    101 x\n",
        "NCop                    609 x\n",
        "Nega                   6058 x\n",
        "Objc                  20816 x\n",
        "PrAd                     84 x\n",
        "PrcS                      8 x\n",
        "PreC                  17765 x\n",
        "PreO                   5514 x\n",
        "PreS                    778 x\n",
        "Pred                  57046 x\n",
        "PtcO                    166 x\n",
        "Ques                   1275 x\n",
        "Rela                   6338 x\n",
        "Subj                  28957 x\n",
        "Supp                    296 x\n",
        "Time                   3551 x\n",
        "Unkn                  11367 x\n",
        "Voct                   1524 x\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Pick up the complements(s)\n",
      "\n",
      "Also collect the lexemes of the verbs in the verb phrases."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "comptype_spec = '''\n",
      "predicate    : Pred PreO PreS PtcO\n",
      "subject      : Subj PreS\n",
      "object       : Objc PreO PtcO\n",
      "complement   : Cmpl PreC\n",
      "adjunct      : Adju PrAd\n",
      "situation    : Loca Time\n",
      "rest         : Modi Supp\n",
      "unclassified : *\n",
      "'''\n",
      "\n",
      "comptype_order = []\n",
      "comptype_inv = {}\n",
      "comptype = {}\n",
      "\n",
      "lines = comptype_spec.split('\\n')\n",
      "l = 0\n",
      "for line in lines:\n",
      "    if line.strip() == '': continue\n",
      "    (ctstr, funcstr) = line.split(':')\n",
      "    ctype = ctstr.strip()\n",
      "    functions = funcstr.strip().split()\n",
      "    comptype_order.append(ctype)\n",
      "    comptype_inv[ctype] = l\n",
      "    for func in functions:\n",
      "        comptype[func] = l\n",
      "    l += 1\n",
      "\n",
      "vp_lexemes = {}\n",
      "clause_phrases = collections.defaultdict(lambda: collections.defaultdict(lambda: []))\n",
      "\n",
      "for clause in clause_order:\n",
      "    phrases = children[clause]\n",
      "    verbs = []\n",
      "    for p in phrases:\n",
      "        cpt = comptype.get(F.function.v(p), comptype_inv['unclassified'])\n",
      "        clause_phrases[cpt][clause].append(p)\n",
      "        if cpt == comptype_inv['predicate']:\n",
      "            for word in children[p]:\n",
      "                if F.sp.v(word) == 'verb':\n",
      "                    verbs.append(F.lex.v(word).rstrip('[/='))\n",
      "    vp_lexemes[clause] = ' '.join(verbs)\n",
      "\n",
      "\n",
      "phrase_distribution = collections.defaultdict(lambda: collections.defaultdict(lambda:0))\n",
      "for ctp in sorted(clause_phrases):\n",
      "    for clause in clause_phrases[ctp]:\n",
      "        phrase_distribution[ctp][len(clause_phrases[ctp][clause])] += 1\n",
      "    \n",
      "msg(\"{} clauses\".format(\n",
      "    nclauses, \n",
      "))\n",
      "\n",
      "maxnphrases = {}\n",
      "for ctp in sorted(phrase_distribution):\n",
      "    for n in sorted(phrase_distribution[ctp]):\n",
      "        maxnphrases[ctp] = n\n",
      "        print(\"{:>5} clauses with {:>2} {}{}\".format(\n",
      "            phrase_distribution[ctp][n], \n",
      "            n, \n",
      "            comptype_order[ctp], \n",
      "            's' if n != 1 else '',\n",
      "        ))\n",
      "for ctp in sorted(maxnphrases):\n",
      "    print(\"There are at most {} {}s in a clause\".format(maxnphrases[ctp], comptype_order[ctp]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s 87978 clauses\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "57046 clauses with  1 predicate\n",
        "29735 clauses with  1 subject\n",
        "24446 clauses with  1 object\n",
        "  990 clauses with  2 objects\n",
        "   15 clauses with  3 objects\n",
        "    5 clauses with  4 objects\n",
        "    1 clauses with  5 objects\n",
        "37168 clauses with  1 complement\n",
        " 4180 clauses with  2 complements\n",
        "   59 clauses with  3 complements\n",
        "    1 clauses with  4 complements\n",
        "    1 clauses with  5 complements\n",
        " 7857 clauses with  1 adjunct\n",
        "  451 clauses with  2 adjuncts\n",
        "   54 clauses with  3 adjuncts\n",
        "    5 clauses with  4 adjuncts\n",
        " 5352 clauses with  1 situation\n",
        "  286 clauses with  2 situations\n",
        "   40 clauses with  3 situations\n",
        "    3 clauses with  4 situations\n",
        "    1 clauses with  5 situations\n",
        " 3819 clauses with  1 rest\n",
        "   87 clauses with  2 rests\n",
        "    2 clauses with  3 rests\n",
        "49710 clauses with  1 unclassified\n",
        " 8472 clauses with  2 unclassifieds\n",
        " 1987 clauses with  3 unclassifieds\n",
        "  593 clauses with  4 unclassifieds\n",
        "  190 clauses with  5 unclassifieds\n",
        "   64 clauses with  6 unclassifieds\n",
        "   29 clauses with  7 unclassifieds\n",
        "   10 clauses with  8 unclassifieds\n",
        "    5 clauses with  9 unclassifieds\n",
        "    1 clauses with 10 unclassifieds\n",
        "    1 clauses with 13 unclassifieds\n",
        "There are at most 1 predicates in a clause\n",
        "There are at most 1 subjects in a clause\n",
        "There are at most 5 objects in a clause\n",
        "There are at most 5 complements in a clause\n",
        "There are at most 4 adjuncts in a clause\n",
        "There are at most 5 situations in a clause\n",
        "There are at most 3 rests in a clause\n",
        "There are at most 13 unclassifieds in a clause\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Print the complete data\n",
      "\n",
      "We output everything as a tab separated file.\n",
      "If a complement type occurs multiple times in a clause, they will occupy separate columns.\n",
      "We know the maximum number of times that each complement type actually occurs.\n",
      "\n",
      "There are also statistics columns, they contain the number of occurrences for each complement type in that clause.\n",
      "Handy for sorting."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "of = outfile('clauses.csv')\n",
      "header = 'passage\\tverblex\\t'\n",
      "for cpt in range(len(comptype_order) - 1):\n",
      "    header += '#{}\\t'.format(comptype_order[cpt])\n",
      "for cpt in range(len(comptype_order) - 1):\n",
      "    for i in range(maxnphrases[cpt]):\n",
      "        header += '{}{}\\t'.format(comptype_order[cpt], i + 1)\n",
      "header += 'clause\\n'\n",
      "of.write(header)\n",
      "\n",
      "for clause in clause_order:\n",
      "    passage = '{} {}:{}'.format(*clause_passage[clause])\n",
      "    verb_lex = vp_lexemes[clause]\n",
      "    complements = []\n",
      "    stats = []\n",
      "    for cpt in range(len(comptype_order) - 1):\n",
      "        phrases = clause_phrases[cpt][clause]\n",
      "        nphrases = len(phrases)\n",
      "        stats.append(str(nphrases))\n",
      "        for i in range(maxnphrases[cpt]):\n",
      "            complements.append(node_transcr[phrases[i]] if i < nphrases else '')\n",
      "\n",
      "    of.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(\n",
      "        passage, \n",
      "        verb_lex, \n",
      "        '\\t'.join(stats),\n",
      "        '\\t'.join(complements),\n",
      "        node_transcr[clause],\n",
      "    ))\n",
      "of.close()\n",
      "msg(\"{} clauses\".format(nclauses))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    38s 87978 clauses\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}