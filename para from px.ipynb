{
 "metadata": {
  "name": "",
  "signature": "sha256:572ace4f18062cfc08f8f0d6c6afd91577073953ca0b9ac520db107e304046d5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
      "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
      "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Paragraphs from the px files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import collections\n",
      "import os\n",
      "import re\n",
      "import gzip\n",
      "from IPython.display import display, HTML, FileLinks\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "import laf\n",
      "from laf.fabric import LafFabric\n",
      "from etcbc.preprocess import prepare\n",
      "fabric = LafFabric()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.2.12\n",
        "http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Create annotations from px file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API=fabric.load('bhs4', '--', 'can', {\n",
      "    \"xmlids\": {\"node\": True, \"edge\": False},\n",
      "    \"features\": ('''\n",
      "        otype number label\n",
      "    ''',\n",
      "    '''\n",
      "    '''),\n",
      "    \"prepare\": prepare,\n",
      "}, verbose='DETAIL')\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: USING DATA COMPILED AT: 2014-06-17T12-19-48\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.08s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.14s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.19s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.60s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.66s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.73s DETAIL: load main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.91s DETAIL: load main: X. [node]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.88s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.86s DETAIL: load main: F.shebanq_ft_number [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.55s DETAIL: load main: F.shebanq_sft_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.56s LOGFILE=/Users/dirk/laf-fabric-output/bhs4/can/__log__can.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.56s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.63s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.11s INFO: DATA LOADED FROM SOURCE bhs4 AND ANNOX -- FOR TASK can AT 2014-06-25T14-21-52\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Preparation: mapping between clause atom numbers and nodes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_can_mappings():\n",
      "    ca_labn2id = {}\n",
      "    ca_id2labn = {}\n",
      "\n",
      "    cur_subtract = 0\n",
      "    cur_chapter_cas = 0\n",
      "    for n in NN():\n",
      "        otype = F.otype.v(n)\n",
      "        if otype == 'verse':\n",
      "            cur_label = F.label.v(n)\n",
      "        elif otype == 'chapter':\n",
      "            cur_subtract += cur_chapter_cas\n",
      "            cur_chapter_cas = 0\n",
      "        elif otype == 'book':\n",
      "            cur_subtract = 0\n",
      "            cur_chapter_cas = 0\n",
      "        elif otype == 'clause_atom':\n",
      "            cur_chapter_cas += 1\n",
      "            nm = int(F.number.v(n)) - cur_subtract\n",
      "            ca_labn2id[(cur_label, nm)] = n\n",
      "            ca_id2labn[n] = (cur_label, nm)\n",
      "    return (ca_labn2id, ca_id2labn)\n",
      "\n",
      "msg(\"Making mappings\")\n",
      "(ca_labn2id, ca_id2labn) = make_can_mappings()\n",
      "msg(\"End making mappings: {}={} clauses\".format(len(ca_labn2id), len(ca_id2labn)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.89s Making mappings\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.16s End making mappings: 90209=90209 clauses\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Read and convert the px files, generate the annotation file and put it in place"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_px(px_file):\n",
      "    data = []\n",
      "    not_found = set()\n",
      "    px_handle = open('{}/{}'.format(data_dir, px_file))\n",
      "    ln = 0\n",
      "    can = 0\n",
      "    featurescan = re.compile(r'LineNr\\s*([0-9]+).*?Pargr:\\s*([0-9.]+)')\n",
      "    cur_label = None\n",
      "    data = []\n",
      "    for line in px_handle:\n",
      "        ln += 1\n",
      "        if line.strip()[0] != '*':\n",
      "            cur_label = line[0:10]\n",
      "            continue\n",
      "        can += 1\n",
      "        features = featurescan.findall(line)\n",
      "        if len(features) == 0:\n",
      "            msg(\"Warning: line {}: no LineNr, Pargr found\".format(ln))\n",
      "        elif len(features) > 1:\n",
      "            msg(\"Warning: line {}: multiple LineNr, Pargr found\".format(ln))\n",
      "        else:\n",
      "            feature = features[0]\n",
      "            the_n = feature[0]\n",
      "            the_para = feature[1]\n",
      "            labn = (cur_label, int(the_n))\n",
      "            if labn not in ca_labn2id:\n",
      "                not_found.add(labn)\n",
      "                continue\n",
      "            data.append((ca_labn2id[labn], the_n, the_para))\n",
      "    px_handle.close()\n",
      "    msg(\"Read {} paragraph annotations\".format(len(data)))\n",
      "    if not_found:\n",
      "        msg(\"Could not find {} label/line entries in index: {}\".format(len(not_found), sorted({lab[0] for lab in not_found})))\n",
      "    else:\n",
      "        msg(\"All label/line entries found in index\")\n",
      "    return data\n",
      "        \n",
      "def create_annots(API, data, spec):\n",
      "    result = []\n",
      "    result.append('''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<graph xmlns=\"http://www.xces.org/ns/GrAF/1.0/\" xmlns:graf=\"http://www.xces.org/ns/GrAF/1.0/\">\n",
      "<graphHeader>\n",
      "    <labelsDecl/>\n",
      "    <dependencies/>\n",
      "    <annotationSpaces/>\n",
      "</graphHeader>''')\n",
      "    aid = 0\n",
      "    features = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(lambda: {})))\n",
      "    \n",
      "    (aspace1, alabel1, fname1) = spec[0]\n",
      "    (aspace2, alabel2, fname2) = spec[1]\n",
      "    for line in data:\n",
      "        node = line[0]\n",
      "        value1 = line[1]\n",
      "        value2 = line[2]\n",
      "        xml_id = X.r(node)\n",
      "        features[aspace1][alabel1][xml_id][fname1] = value1\n",
      "        features[aspace2][alabel2][xml_id][fname2] = value2\n",
      "        \n",
      "    for aspace in features:\n",
      "        for alabel in features[aspace]:\n",
      "            for xml_id in features[aspace][alabel]:\n",
      "                aid += 1\n",
      "                result.append('''<a xml:id=\"a{}\" as=\"{}\" label=\"{}\" ref=\"{}\"><fs>'''.format(aid, aspace, alabel, xml_id))\n",
      "                for fname in features[aspace][alabel][xml_id]:\n",
      "                    value = features[aspace][alabel][xml_id][fname]\n",
      "                    result.append('\\t<f name=\"{}\" value=\"{}\"/>'.format(fname, value))\n",
      "                result.append('</fs></a>')\n",
      "    result.append(\"</graph>\")\n",
      "    return '\\n'.join(result)\n",
      "\n",
      "def create_header(annox_part):\n",
      "    result = []\n",
      "    result.append(\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<documentHeader xmlns=\"http://www.xces.org/ns/GrAF/1.0/\" xmlns:graf=\"http://www.xces.org/ns/GrAF/1.0/\" docId=\"http://persistent-identifier/?identifier=urn:nbn:nl:ui:13-xxx-999\" creator=\"SHEBANQ\" date.created=\"2013-12-05\" version=\"1.0\">\n",
      "  <fileDesc>\n",
      "    <titleStmt>\n",
      "      <title>Literary annotations</title>\n",
      "    </titleStmt>\n",
      "    <extent count=\"0\" unit=\"byte\"/>\n",
      "    <sourceDesc>\n",
      "      <title>Biblia Hebraica Stuttgartentis</title>\n",
      "      <author>tradition</author>\n",
      "      <publisher>Deutsche Bibelgesellschaft</publisher>\n",
      "      <pubDate value=\"1900-00-00\">1900</pubDate>\n",
      "      <pubPlace>Germany</pubPlace>\n",
      "    </sourceDesc>\n",
      "  </fileDesc>\n",
      "  <profileDesc>\n",
      "    <primaryData f.id=\"f.primary\" loc=\"bhs4.txt\"/>\n",
      "\t<langUsage>\n",
      "\t\t<language iso639=\"hbo\"/> <!-- ancient hebrew http://www-01.sil.org/iso639-3/documentation.asp?id=hbo -->\n",
      "\t\t<language iso639=\"arc\"/> <!-- aramaic http://www-01.sil.org/iso639-3/documentation.asp?id=arc -->\n",
      "\t</langUsage>\n",
      "    <annotations>\n",
      "\t\t<annotation f.id=\"f_{key}\" loc=\"{key}.xml\"/>\n",
      "    </annotations>\n",
      "  </profileDesc>\n",
      "</documentHeader>\"\"\".format(key=annox_part))\n",
      "    \n",
      "    return '\\n'.join(result)\n",
      "\n",
      "def deliver_annots(px_base, annox, annox_part, specs):\n",
      "    px_data = read_px(px_base)\n",
      "    annox_dir = \"{}/bhs4/annotations/{}\".format(data_dir, annox)\n",
      "    if not os.path.exists(annox_dir): os.makedirs(annox_dir)\n",
      "    with open(\"{}/_header_.xml\".format(annox_dir), \"w\") as ah: ah.write(create_header(annox_part))\n",
      "    with open(\"{}/{}.xml\".format(annox_dir, annox_part), \"w\") as ah: ah.write(create_annots(API, px_data, specs))\n",
      "\n",
      "deliver_annots('px/px_data', 'px_extra', 'para', (('px', 'ft', 'number_in_ch'), ('px', 'ft', 'pargr')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    15s Read 89346 paragraph annotations\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    15s Could not find 877 label/line entries in index: [' DEUT01,41', ' DEUT01,42', ' DEUT01,43', ' DEUT01,44', ' DEUT01,45', ' DEUT01,46', ' DEUT05,01', ' DEUT05,02', ' DEUT05,03', ' DEUT05,04', ' DEUT05,05', ' DEUT05,06', ' DEUT05,07', ' DEUT05,08', ' DEUT05,09', ' DEUT05,10', ' DEUT05,11', ' DEUT05,12', ' DEUT05,13', ' DEUT05,14', ' DEUT05,15', ' DEUT05,16', ' DEUT05,17', ' DEUT05,18', ' DEUT05,19', ' DEUT05,20', ' DEUT05,21', ' DEUT05,22', ' DEUT05,23', ' DEUT05,24', ' DEUT05,25', ' DEUT05,26', ' DEUT05,27', ' DEUT05,28', ' DEUT05,29', ' DEUT05,30', ' DEUT05,31', ' DEUT05,32', ' DEUT05,33', ' DEUT26,10', ' DEUT26,11', ' DEUT26,12', ' DEUT26,13', ' DEUT26,14', ' DEUT26,15', ' DEUT26,16', ' DEUT26,17', ' DEUT26,18', ' DEUT26,19', ' DEUT33,07', ' DEUT33,08', ' DEUT33,09', ' DEUT33,10', ' DEUT33,11', ' DEUT33,12', ' DEUT33,13', ' DEUT33,14', ' DEUT33,15', ' DEUT33,16', ' DEUT33,17', ' DEUT33,18', ' DEUT33,19', ' DEUT33,20', ' DEUT33,21', ' DEUT33,22', ' DEUT33,23', ' DEUT33,24', ' DEUT33,25', ' DEUT33,26', ' DEUT33,27', ' DEUT33,28', ' DEUT33,29', ' ESR 07,18', ' ESR 07,19', ' ESR 07,20', ' ESR 07,21', ' ESR 07,22', ' ESR 07,23', ' ESR 07,24', ' ESR 07,25', ' ESR 07,27', ' ESR 07,28', ' EXO 06,03', ' EXO 06,04', ' EXO 06,05', ' EXO 06,06', ' EXO 06,07', ' EXO 06,08', ' EXO 06,09', ' EXO 06,10', ' EXO 06,11', ' EXO 06,12', ' EXO 06,13', ' EXO 06,14', ' EXO 06,15', ' EXO 06,16', ' EXO 06,17', ' EXO 06,18', ' EXO 06,19', ' EXO 06,20', ' EXO 06,21', ' EXO 06,22', ' EXO 06,23', ' EXO 06,24', ' EXO 06,25', ' EXO 06,26', ' EXO 06,27', ' EXO 06,28', ' EXO 06,29', ' EXO 06,30', ' GEN 31,49', ' GEN 31,50', ' GEN 31,51', ' GEN 31,52', ' GEN 31,53', ' GEN 31,54', ' JER 30,10', ' JER 30,11', ' JER 30,12', ' JER 30,13', ' JER 30,14', ' JER 30,15', ' JER 30,16', ' JER 30,17', ' JER 30,18', ' JER 30,19', ' JER 30,20', ' JER 30,21', ' JER 30,22', ' JER 30,23', ' JER 30,24', ' JER 34,09', ' JER 34,10', ' JER 34,11', ' JER 34,12', ' JER 34,13', ' JER 34,14', ' JER 34,15', ' JER 34,16', ' JER 34,17', ' JER 34,18', ' JER 34,19', ' JER 34,20', ' JER 34,21', ' JER 34,22', ' JER 37,10', ' JER 37,11', ' JER 37,12', ' JER 37,13', ' JER 37,14', ' JER 37,15', ' JER 37,16', ' JER 37,17', ' JER 37,18', ' JER 37,19', ' JER 37,20', ' JER 37,21', ' JOZ 04,05', ' JOZ 04,06', ' JOZ 04,07', ' JOZ 04,08', ' JOZ 04,09', ' JOZ 04,10', ' JOZ 04,11', ' JOZ 04,12', ' JOZ 04,13', ' JOZ 04,14', ' JOZ 04,15', ' JOZ 04,16', ' JOZ 04,17', ' JOZ 04,18', ' JOZ 04,19', ' JOZ 04,20', ' JOZ 04,21', ' JOZ 04,22', ' JOZ 04,23', ' JOZ 04,24', ' NUM 10,35', ' NUM 10,36', ' PS035,022', ' PS035,023', ' PS035,024', ' PS035,025', ' PS035,026', ' PS035,027', ' PS035,028', ' PS038,013', ' PS038,014', ' PS038,015', ' PS038,016', ' PS038,017', ' PS038,018', ' PS038,019', ' PS038,020', ' PS038,021', ' PS038,022', ' PS038,023', ' PS040,001', ' PS040,002', ' PS040,003', ' PS040,004', ' PS040,007', ' PS040,008', ' PS040,009', ' PS040,010', ' PS040,011', ' PS040,012', ' PS040,013', ' PS040,014', ' PS040,015', ' PS040,016', ' PS040,017', ' PS040,018', ' PS041,008', ' PS041,009', ' PS041,010', ' PS041,011', ' PS041,012', ' PS041,013', ' PS041,014', ' PS042,002', ' PS042,003', ' PS042,004', ' PS042,005', ' PS042,006', ' PS042,007', ' PS042,008', ' PS042,009', ' PS042,010', ' PS042,011', ' PS042,012', ' PS043,004', ' PS043,005', ' PS044,015', ' PS044,016', ' PS044,017', ' PS044,018', ' PS044,019', ' PS044,020', ' PS044,021', ' PS044,022', ' PS044,023', ' PS044,024', ' PS044,025', ' PS044,026', ' PS044,027', ' PS048,002', ' PS048,005', ' PS048,006', ' PS048,007', ' PS048,008', ' PS048,009', ' PS048,010', ' PS048,011', ' PS048,012', ' PS048,013', ' PS048,014', ' PS048,015', ' PS049,015', ' PS049,016', ' PS049,017', ' PS049,018', ' PS049,019', ' PS049,020', ' PS049,021', ' PS051,006', ' PS051,007', ' PS051,008', ' PS051,009', ' PS051,010', ' PS051,011', ' PS051,012', ' PS051,013', ' PS051,014', ' PS051,015', ' PS051,016', ' PS051,017', ' PS051,018', ' PS051,019', ' PS051,020', ' PS052,004', ' PS052,005', ' PS052,006', ' PS052,007', ' PS052,008', ' PS052,009', ' PS052,010', ' PS052,011', ' PS053,006', ' PS053,007', ' PS055,007', ' PS055,008', ' PS055,011', ' PS055,012', ' PS055,013', ' PS055,014', ' PS055,015', ' PS055,016', ' PS055,017', ' PS055,018', ' PS055,019', ' PS055,020', ' PS055,021', ' PS055,022', ' PS055,023', ' PS055,024', ' PS056,004', ' PS056,005', ' PS056,006', ' PS056,007', ' PS056,008', ' PS056,009', ' PS056,010', ' PS056,011', ' PS056,012', ' PS056,013', ' PS056,014', ' PS057,010', ' PS057,011', ' PS057,012', ' PS058,007', ' PS058,008', ' PS058,009', ' PS058,010', ' PS058,011', ' PS058,012', ' PS059,005', ' PS059,006', ' PS059,007', ' PS059,008', ' PS059,009', ' PS059,010', ' PS059,011', ' PS059,012', ' PS059,013', ' PS059,014', ' PS059,015', ' PS059,016', ' PS059,017', ' PS059,018', ' PS060,010', ' PS060,011', ' PS060,012', ' PS060,013', ' PS060,014', ' PS061,003', ' PS061,004', ' PS061,005', ' PS061,006', ' PS061,007', ' PS061,008', ' PS061,009', ' PS062,001', ' PS062,002', ' PS062,003', ' PS062,004', ' PS062,005', ' PS062,006', ' PS062,007', ' PS063,011', ' PS063,012', ' PS065,007', ' PS065,008', ' PS065,009', ' PS065,010', ' PS065,011', ' PS065,012', ' PS065,013', ' PS065,014', ' PS066,008', ' PS066,009', ' PS066,010', ' PS066,011', ' PS066,012', ' PS066,013', ' PS066,014', ' PS066,015', ' PS066,016', ' PS066,017', ' PS066,018', ' PS066,019', ' PS066,020', ' PS068,005', ' PS068,007', ' PS068,008', ' PS068,009', ' PS068,010', ' PS068,011', ' PS068,012', ' PS068,013', ' PS068,014', ' PS068,015', ' PS068,016', ' PS068,017', ' PS068,018', ' PS068,019', ' PS068,020', ' PS068,021', ' PS068,022', ' PS068,023', ' PS068,024', ' PS068,025', ' PS068,026', ' PS068,027', ' PS068,028', ' PS068,029', ' PS068,030', ' PS068,031', ' PS068,032', ' PS068,033', ' PS068,034', ' PS068,035', ' PS068,036', ' PS069,015', ' PS069,016', ' PS069,017', ' PS069,018', ' PS069,019', ' PS069,020', ' PS069,021', ' PS069,022', ' PS069,023', ' PS069,024', ' PS069,025', ' PS069,026', ' PS069,027', ' PS069,028', ' PS069,029', ' PS069,030', ' PS069,031', ' PS069,032', ' PS069,033', ' PS069,034', ' PS069,035', ' PS069,036', ' PS069,037', ' PS070,003', ' PS070,004', ' PS070,005', ' PS070,006', ' PS071,013', ' PS071,014', ' PS071,015', ' PS071,016', ' PS071,017', ' PS071,018', ' PS071,019', ' PS071,020', ' PS071,021', ' PS071,022', ' PS071,023', ' PS071,024', ' PS072,006', ' PS072,007', ' PS072,008', ' PS072,009', ' PS072,010', ' PS072,011', ' PS072,012', ' PS072,013', ' PS072,014', ' PS072,015', ' PS072,016', ' PS072,017', ' PS072,018', ' PS072,019', ' PS072,020', ' PS073,001', ' PS073,002', ' PS073,003', ' PS073,004', ' PS073,005', ' PS073,006', ' PS073,007', ' PS073,008', ' PS073,009', ' PS073,010', ' PS073,011', ' PS074,003', ' PS074,004', ' PS074,005', ' PS074,007', ' PS074,008', ' PS074,009', ' PS074,010', ' PS074,011', ' PS074,012', ' PS074,013', ' PS074,014', ' PS074,015', ' PS074,016', ' PS074,017', ' PS074,018', ' PS074,023', ' PS077,015', ' PS077,016', ' PS077,017', ' PS077,018', ' PS077,019', ' PS077,020', ' PS077,021', ' RUTH02,08', ' RUTH02,09', ' RUTH02,10', ' RUTH02,11', ' RUTH02,12', ' RUTH02,13', ' RUTH02,14', ' RUTH02,15', ' RUTH02,16', ' RUTH02,17', ' RUTH02,18', ' RUTH02,19', ' RUTH02,20', ' RUTH02,21', ' RUTH02,22', ' RUTH02,23', 'IICHR11,04', 'IICHR11,05', 'IICHR11,06', 'IICHR11,07', 'IICHR11,08', 'IICHR11,09', 'IICHR11,10', 'IICHR11,11', 'IICHR11,12', 'IICHR11,13', 'IICHR11,14', 'IICHR11,15', 'IICHR11,16', 'IICHR11,17', 'IICHR11,18', 'IICHR11,19', 'IICHR11,20', 'IICHR11,21', 'IICHR11,22', 'IICHR11,23', 'IIKON06,02', 'IIKON06,03', 'IIKON06,04', 'IIKON06,05', 'IIKON06,06', 'IIKON06,07', 'IIKON06,08', 'IIKON06,09', 'IIKON06,10', 'IIKON06,11', 'IIKON06,12', 'IIKON06,13', 'IIKON06,14', 'IIKON06,15', 'IIKON06,16', 'IIKON06,17', 'IIKON06,18', 'IIKON06,19', 'IIKON06,20', 'IIKON06,21', 'IIKON06,22', 'IIKON06,23', 'IIKON06,24', 'IIKON06,25', 'IIKON06,26', 'IIKON06,27', 'IIKON06,28', 'IIKON06,29', 'IIKON06,30', 'IIKON06,31', 'IIKON06,32', 'IIKON06,33', 'ISAM 14,38', 'ISAM 14,39', 'ISAM 14,40', 'ISAM 14,41', 'ISAM 14,42', 'ISAM 14,43', 'ISAM 14,44', 'ISAM 14,45', 'ISAM 14,46', 'ISAM 14,47', 'ISAM 14,48', 'ISAM 14,49', 'ISAM 14,50', 'ISAM 14,51', 'ISAM 14,52']\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Checking: loading the new features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API=fabric.load('bhs4', 'px_extra', 'can', {\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": ('''\n",
      "        otype number label\n",
      "        number_in_ch pargr\n",
      "    ''',\n",
      "    '''\n",
      "    '''),\n",
      "    \"prepare\": prepare,\n",
      "}, verbose='DETAIL')\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: USING DATA COMPILED AT: 2014-06-17T12-19-48\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s BEGIN COMPILE a: px_extra\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: load main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.25s DETAIL: load main: X. [e]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.08s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.14s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.19s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.24s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.68s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.75s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.83s LOGFILE=/Users/dirk/laf-fabric-data/bhs4/bin/A/px_extra/__log__compile__.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.83s PARSING ANNOTATION FILES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.83s INFO: parsing para.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.74s INFO: END PARSING\n",
        "         0 good   regions  and     0 faulty ones\n",
        "         0 linked nodes    and     0 unlinked ones\n",
        "         0 good   edges    and     0 faulty ones\n",
        "     89346 good   annots   and     0 faulty ones\n",
        "    178692 good   features and     0 faulty ones\n",
        "     89346 distinct xml identifiers\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.74s MODELING RESULT FILES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.74s INFO: CONNECTIVITY\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.95s WRITING RESULT FILES for a\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.95s DETAIL: write annox: F.px_ft_number_in_ch [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.03s DETAIL: write annox: F.px_ft_pargr [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.10s END   COMPILE a: px_extra\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.78s INFO: USING DATA COMPILED AT: 2014-06-25T14-22-29\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.79s DETAIL: keep main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.79s DETAIL: keep main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.79s DETAIL: keep main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.79s DETAIL: keep main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.79s DETAIL: keep main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.79s DETAIL: keep main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.79s DETAIL: keep main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.79s DETAIL: keep main: F.shebanq_ft_number [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.79s DETAIL: keep main: F.shebanq_sft_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.79s DETAIL: clear main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.79s DETAIL: clear main: X. [node]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.79s DETAIL: load main: F.px_ft_number_in_ch [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.80s DETAIL: load main: F.px_ft_pargr [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.80s DETAIL: load annox: F.px_ft_number_in_ch [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.86s DETAIL: load annox: F.px_ft_pargr [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.93s DETAIL: load annox: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.93s DETAIL: load annox: F.shebanq_ft_number [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.93s DETAIL: load annox: F.shebanq_sft_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.93s LOGFILE=/Users/dirk/laf-fabric-output/bhs4/can/__log__can.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.93s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.01s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  9.58s INFO: DATA LOADED FROM SOURCE bhs4 AND ANNOX px_extra FOR TASK can AT 2014-06-25T14-22-30\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Inspecting all objects that got new features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ph = outfile('paras.txt')\n",
      "cur_label = None\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        cur_label = F.label.v(n)\n",
      "    elif otype == 'clause_atom':\n",
      "        nm = F.number_in_ch.v(n)\n",
      "        if nm:\n",
      "            ph.write(\"{}: {}: para = {}\\n\".format(cur_label, nm, F.pargr.v(n)))\n",
      "ph.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 100 {my_file('paras.txt')}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " GEN 01,01: 1: para = \r\n",
        " GEN 01,02: 2: para = \r\n",
        " GEN 01,02: 3: para = \r\n",
        " GEN 01,02: 4: para = \r\n",
        " GEN 01,03: 5: para = \r\n",
        " GEN 01,03: 6: para = \r\n",
        " GEN 01,03: 7: para = \r\n",
        " GEN 01,04: 8: para = \r\n",
        " GEN 01,04: 9: para = \r\n",
        " GEN 01,04: 10: para = \r\n",
        " GEN 01,05: 11: para = \r\n",
        " GEN 01,05: 12: para = \r\n",
        " GEN 01,05: 13: para = \r\n",
        " GEN 01,05: 14: para = \r\n",
        " GEN 01,05: 15: para = \r\n",
        " GEN 01,06: 16: para = \r\n",
        " GEN 01,06: 17: para = \r\n",
        " GEN 01,06: 18: para = \r\n",
        " GEN 01,07: 19: para = \r\n",
        " GEN 01,07: 20: para = \r\n",
        " GEN 01,07: 21: para = \r\n",
        " GEN 01,07: 22: para = \r\n",
        " GEN 01,07: 23: para = \r\n",
        " GEN 01,07: 24: para = \r\n",
        " GEN 01,08: 25: para = \r\n",
        " GEN 01,08: 26: para = \r\n",
        " GEN 01,08: 27: para = \r\n",
        " GEN 01,08: 28: para = \r\n",
        " GEN 01,09: 29: para = \r\n",
        " GEN 01,09: 30: para = \r\n",
        " GEN 01,09: 31: para = \r\n",
        " GEN 01,09: 32: para = \r\n",
        " GEN 01,10: 33: para = \r\n",
        " GEN 01,10: 34: para = \r\n",
        " GEN 01,10: 35: para = \r\n",
        " GEN 01,10: 36: para = \r\n",
        " GEN 01,11: 37: para = \r\n",
        " GEN 01,11: 38: para = \r\n",
        " GEN 01,11: 39: para = \r\n",
        " GEN 01,11: 40: para = \r\n",
        " GEN 01,11: 41: para = \r\n",
        " GEN 01,11: 42: para = \r\n",
        " GEN 01,11: 43: para = \r\n",
        " GEN 01,11: 44: para = \r\n",
        " GEN 01,12: 45: para = \r\n",
        " GEN 01,12: 46: para = \r\n",
        " GEN 01,12: 47: para = \r\n",
        " GEN 01,12: 48: para = \r\n",
        " GEN 01,12: 49: para = \r\n",
        " GEN 01,12: 50: para = \r\n",
        " GEN 01,12: 51: para = \r\n",
        " GEN 01,12: 52: para = \r\n",
        " GEN 01,13: 53: para = \r\n",
        " GEN 01,13: 54: para = \r\n",
        " GEN 01,13: 55: para = \r\n",
        " GEN 01,14: 56: para = \r\n",
        " GEN 01,14: 57: para = \r\n",
        " GEN 01,14: 58: para = \r\n",
        " GEN 01,14: 59: para = \r\n",
        " GEN 01,15: 60: para = \r\n",
        " GEN 01,15: 61: para = \r\n",
        " GEN 01,15: 62: para = \r\n",
        " GEN 01,16: 63: para = \r\n",
        " GEN 01,16: 64: para = \r\n",
        " GEN 01,16: 65: para = \r\n",
        " GEN 01,16: 66: para = \r\n",
        " GEN 01,17: 67: para = \r\n",
        " GEN 01,17: 68: para = \r\n",
        " GEN 01,18: 69: para = \r\n",
        " GEN 01,18: 70: para = \r\n",
        " GEN 01,18: 71: para = \r\n",
        " GEN 01,18: 72: para = \r\n",
        " GEN 01,19: 73: para = \r\n",
        " GEN 01,19: 74: para = \r\n",
        " GEN 01,19: 75: para = \r\n",
        " GEN 01,20: 76: para = \r\n",
        " GEN 01,20: 77: para = \r\n",
        " GEN 01,20: 78: para = \r\n",
        " GEN 01,21: 79: para = \r\n",
        " GEN 01,21: 80: para = \r\n",
        " GEN 01,21: 81: para = \r\n",
        " GEN 01,21: 82: para = \r\n",
        " GEN 01,21: 83: para = \r\n",
        " GEN 01,21: 84: para = \r\n",
        " GEN 01,21: 85: para = \r\n",
        " GEN 01,21: 86: para = \r\n",
        " GEN 01,22: 87: para = \r\n",
        " GEN 01,22: 88: para = \r\n",
        " GEN 01,22: 89: para = \r\n",
        " GEN 01,22: 90: para = \r\n",
        " GEN 01,22: 91: para = \r\n",
        " GEN 01,22: 92: para = \r\n",
        " GEN 01,23: 93: para = \r\n",
        " GEN 01,23: 94: para = \r\n",
        " GEN 01,23: 95: para = \r\n",
        " GEN 01,24: 96: para = \r\n",
        " GEN 01,24: 97: para = \r\n",
        " GEN 01,24: 98: para = \r\n",
        " GEN 01,24: 99: para = \r\n",
        " GEN 01,25: 100: para = \r\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}