{
 "metadata": {
  "name": "",
  "signature": "sha256:de3bd739f9e71992615af630029154531f3943607958a6604e1f016a4d3091c3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
      "<a href=\"http://www.persistent-identifier.nl/?identifier=urn%3Anbn%3Anl%3Aui%3A13-048i-71\" target=\"_blank\"><img align=\"left\"src=\"images/etcbc4easy-small.png\"/></a>\n",
      "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
      "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Lexicon data\n",
      "\n",
      "We add the lexcion data as extra features to the ETCBC4 database.\n",
      "\n",
      "For every word, we add *lexical* features, i.e. features that are obtained from looking up the word in the lexicon and then reading off extra attributes from the lexical entry.\n",
      "\n",
      "We add these features into the ``etcbc4`` annotation space, with label ``lex``.\n",
      "These are the extra features:\n",
      "\n",
      "* **lid** a fresh id, to be used in applications, unique over **entryid** and **lan**\n",
      "* **lan** the language of the entry, in ISO 639-3 abbreviation\n",
      "* **entryid** the string used as entry in the lexicon and as value of the ``lex`` feature in the text\n",
      "* **entry** the unpointed transliteration (= **entryid** without disambiguation marks)\n",
      "* **entry_heb** the unpointed hebrew representation, obtained by untransliterating **entry**\n",
      "* (shortly) **g_entry** the pointed transliteration, without disambiguation marks, obtained from ``vc``\n",
      "* (shortly) **g_entry_heb** the pointed hebrew representation, obtained by untransliterating **g_entry**\n",
      "* (shortly) **root** the root, obtained from ``rt``\n",
      "* **gloss** the gloss from ``gl``\n",
      "* **pos** the part of speech, obtained from ``sp``\n",
      "* **nametype** the type of named entity, obtained from ``sm``\n",
      "* **subpos** subtype of part of speech, obtained from ``ls`` (aka *lexical set*)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import display, HTML, FileLinks\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "import laf\n",
      "from laf.fabric import LafFabric\n",
      "from etcbc.preprocess import prepare\n",
      "from etcbc.extra import ExtraData\n",
      "fabric = LafFabric()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.4.5\n",
        "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
        "Feature doc: http://shebanq-doc.readthedocs.org/en/latest/texts/welcome.html\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Create annotations from lexicon file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API=fabric.load('etcbc4', '--', 'lexicon', {\n",
      "    \"xmlids\": {\"node\": True, \"edge\": False},\n",
      "    \"features\": ('''\n",
      "        otype lex\n",
      "    ''',\n",
      "    '''\n",
      "    '''),\n",
      "    \"prepare\": prepare,\n",
      "}, verbose='DETAIL')\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.10s INFO: USING DATA COMPILED AT: 2014-07-23T09-31-37\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.10s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.11s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.81s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.88s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.94s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.54s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.61s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.70s DETAIL: load main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.18s DETAIL: load main: X. [node]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.06s DETAIL: load main: F.etcbc4_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.97s DETAIL: load main: F.etcbc4_ft_lex [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.18s LOGFILE=/Users/dirk/laf-fabric-output/etcbc4/lexicon/__log__lexicon.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.19s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.27s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.90s INFO: DATA LOADED FROM SOURCE etcbc4 AND ANNOX -- FOR TASK lexicon AT 2014-10-13T14-54-32\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Method to read lexical data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "do_fields = dict(\n",
      "    id=1, lan=1, entryid='i', \n",
      "    entry=1, entry_heb=1,\n",
      "    g_entry='*', g_entry_heb='*',root='*',\n",
      "    pos=1, nametype=1, subpos=1,\n",
      "    gender=0, numbr=0, person=0,\n",
      "    gloss=1,\n",
      ")\n",
      "\n",
      "def read_px(lex_file):\n",
      "    lexicon = {}\n",
      "    id_field = -1\n",
      "    fieldsuppress = set()\n",
      "    fieldnum = collections.OrderedDict()\n",
      "    lex_handle = open(lex_file)\n",
      "    for line in lex_handle:\n",
      "        ln += 1\n",
      "        line = line.strip()\n",
      "        if ln == 1:\n",
      "            nf = -1\n",
      "            for f in line.split('\\t'):\n",
      "                nf += 1\n",
      "                finfo = do_fields[f]\n",
      "                if finfo == 'i':\n",
      "                    id_field = nf\n",
      "                elif finfo != 0:\n",
      "                    fieldnum[f] = nf\n",
      "                if finfo == '*':\n",
      "                    fieldsuppress.add(f)\n",
      "            continue\n",
      "        values = line.split('\\t')\n",
      "        row = []\n",
      "        for f in fieldnum:\n",
      "            this_value = values[fieldnum[f]]\n",
      "            if f in fieldsuppress:\n",
      "                this_value = '*' * len(this_value)\n",
      "            row.append(this_value)\n",
      "            lid = values[id_field]\n",
      "            lexicon[lid] = tuple(row)\n",
      "    lex_handle.close()\n",
      "    msg(\"Read {} lexicon entries\".format(len(lexicon)))\n",
      "    \n",
      "    for n in NN():\n",
      "        if F.otype.v(n) != 'word': continue\n",
      "        # lookup word in lexicon, and put attributes in data\n",
      "    return data\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Integrating the lexicon data\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lex = ExtraData(API)\n",
      "lex.deliver_annots('lexicon/lex_data', 'lexicon', 'lex', read_lex, (\n",
      "        ('etcbc4', 'lex', 'id'),\n",
      "        ('etcbc4', 'lex', 'lan'),\n",
      "        ('etcbc4', 'lex', 'entryid'),\n",
      "        ('etcbc4', 'lex', 'entry'),\n",
      "        ('etcbc4', 'lex', 'entry_heb'),\n",
      "        ('etcbc4', 'lex', 'g_entry'),\n",
      "        ('etcbc4', 'lex', 'g_entry_heb'),\n",
      "        ('etcbc4', 'lex', 'root'),\n",
      "        ('etcbc4', 'lex', 'pos'),\n",
      "        ('etcbc4', 'lex', 'nametype'),\n",
      "        ('etcbc4', 'lex', 'subpos'),\n",
      "        ('etcbc4', 'lex', 'gloss'),\n",
      "    ),\n",
      "    {'title': 'Lexicon lookups', 'date': '2014'},\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.93s Making mappings between clause atoms in PX and nodes in LAF\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.85s End making mappings: 90144=90144 clauses\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.80s Read 90144 paragraph annotations\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  8.81s All label/line entries found in index\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Checking: loading the new features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API=fabric.load('etcbc4', 'px', 'can', {\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": ('''\n",
      "        otype number label\n",
      "        instruction number_in_ch pargr\n",
      "    ''',\n",
      "    '''\n",
      "    '''),\n",
      "    \"prepare\": prepare,\n",
      "}, verbose='DETAIL')\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s INFO: USING DATA COMPILED AT: 2014-07-23T09-31-37\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s BEGIN COMPILE a: px\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: load main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.73s DETAIL: load main: X. [e]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.90s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.96s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.02s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.07s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.76s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.84s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.93s LOGFILE=/Users/dirk/laf-fabric-data/etcbc4/bin/A/px/__log__compile__.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.93s PARSING ANNOTATION FILES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.00s INFO: parsing para.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    10s INFO: END PARSING\n",
        "         0 good   regions  and     0 faulty ones\n",
        "         0 linked nodes    and     0 unlinked ones\n",
        "         0 good   edges    and     0 faulty ones\n",
        "     90144 good   annots   and     0 faulty ones\n",
        "    270432 good   features and     0 faulty ones\n",
        "     90144 distinct xml identifiers\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    10s MODELING RESULT FILES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    10s INFO: CONNECTIVITY\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s WRITING RESULT FILES for a\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: write annox: F.etcbc4_px_instruction [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: write annox: F.etcbc4_px_number_in_ch [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: write annox: F.etcbc4_px_pargr [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s END   COMPILE a: px\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s INFO: USING DATA COMPILED AT: 2014-09-29T15-29-45\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: keep main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: keep main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: keep main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: keep main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: keep main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: keep main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: keep main: F.etcbc4_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: keep main: F.etcbc4_ft_number [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: keep main: F.etcbc4_sft_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: clear main: X. [node]  -> \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: clear main: X. [node]  <- \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: clear main: F.etcbc4_db_monads [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: load main: F.etcbc4_px_instruction [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: load main: F.etcbc4_px_number_in_ch [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: load main: F.etcbc4_px_pargr [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: load annox: F.etcbc4_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: load annox: F.etcbc4_ft_number [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: load annox: F.etcbc4_px_instruction [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: load annox: F.etcbc4_px_number_in_ch [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: load annox: F.etcbc4_px_pargr [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: load annox: F.etcbc4_sft_label [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: prep prep: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s DETAIL: prep prep: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    12s INFO: DATA LOADED FROM SOURCE etcbc4 AND ANNOX px FOR TASK can AT 2014-09-29T15-29-46\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Inspecting all objects that got new features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ph = outfile('paras.txt')\n",
      "cur_label = None\n",
      "for n in NN():\n",
      "    otype = F.otype.v(n)\n",
      "    if otype == 'verse':\n",
      "        cur_label = F.label.v(n)\n",
      "    elif otype == 'clause_atom':\n",
      "        nm = F.number_in_ch.v(n)\n",
      "        if nm:\n",
      "            ph.write(\"{}: instruction = {}; {}; para = {}\\n\".format(cur_label, nm, F.instruction.v(n), F.pargr.v(n)))\n",
      "ph.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 100 {my_file('paras.txt')}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " GEN 01,01: instruction = 1; .N; para = 1\r\n",
        " GEN 01,02: instruction = 2; .#; para = 1.1\r\n",
        " GEN 01,02: instruction = 3; ..; para = 1.1\r\n",
        " GEN 01,02: instruction = 4; ..; para = 1.1\r\n",
        " GEN 01,03: instruction = 5; .#; para = 1.2\r\n",
        " GEN 01,03: instruction = 6; .q; para = 1.2.1\r\n",
        " GEN 01,03: instruction = 7; .#; para = 1.2.2\r\n",
        " GEN 01,04: instruction = 8; .#; para = 1.2.3\r\n",
        " GEN 01,04: instruction = 9; ..; para = 1.2.3\r\n",
        " GEN 01,04: instruction = 10; .#; para = 1.2.4\r\n",
        " GEN 01,05: instruction = 11; .#; para = 1.2.5\r\n",
        " GEN 01,05: instruction = 12; ..; para = 1.2.5\r\n",
        " GEN 01,05: instruction = 13; .#; para = 1.2.5.1\r\n",
        " GEN 01,05: instruction = 14; .#; para = 1.2.5.2\r\n",
        " GEN 01,05: instruction = 15; ..; para = 1.2.5.2\r\n",
        " GEN 01,06: instruction = 16; .#; para = 1.3\r\n",
        " GEN 01,06: instruction = 17; .q; para = 1.3.1\r\n",
        " GEN 01,06: instruction = 18; ..; para = 1.3.1\r\n",
        " GEN 01,07: instruction = 19; .#; para = 1.3.2\r\n",
        " GEN 01,07: instruction = 20; ..; para = 1.3.2\r\n",
        " GEN 01,07: instruction = 21; .e; para = 1.3.2\r\n",
        " GEN 01,07: instruction = 22; d.; para = 1.3.2\r\n",
        " GEN 01,07: instruction = 23; ..; para = 1.3.2\r\n",
        " GEN 01,07: instruction = 24; ..; para = 1.3.2\r\n",
        " GEN 01,08: instruction = 25; .#; para = 1.3.2.1\r\n",
        " GEN 01,08: instruction = 26; .#; para = 1.3.2.1.1\r\n",
        " GEN 01,08: instruction = 27; .#; para = 1.3.2.1.2\r\n",
        " GEN 01,08: instruction = 28; ..; para = 1.3.2.1.2\r\n",
        " GEN 01,09: instruction = 29; .#; para = 1.4\r\n",
        " GEN 01,09: instruction = 30; .q; para = 1.4.1\r\n",
        " GEN 01,09: instruction = 31; ..; para = 1.4.1\r\n",
        " GEN 01,09: instruction = 32; ..; para = 1.4\r\n",
        " GEN 01,10: instruction = 33; .#; para = 1.4.2\r\n",
        " GEN 01,10: instruction = 34; ..; para = 1.4.2\r\n",
        " GEN 01,10: instruction = 35; .#; para = 1.4.3\r\n",
        " GEN 01,10: instruction = 36; ..; para = 1.4.3\r\n",
        " GEN 01,11: instruction = 37; .#; para = 1.5\r\n",
        " GEN 01,11: instruction = 38; .q; para = 1.5.1\r\n",
        " GEN 01,11: instruction = 39; .e; para = 1.5.1\r\n",
        " GEN 01,11: instruction = 40; d.; para = 1.5.1\r\n",
        " GEN 01,11: instruction = 41; ..; para = 1.5.1\r\n",
        " GEN 01,11: instruction = 42; .e; para = 1.5.1\r\n",
        " GEN 01,11: instruction = 43; d.; para = 1.5.1\r\n",
        " GEN 01,11: instruction = 44; ..; para = 1.5\r\n",
        " GEN 01,12: instruction = 45; .#; para = 1.5.2\r\n",
        " GEN 01,12: instruction = 46; .e; para = 1.5.2\r\n",
        " GEN 01,12: instruction = 47; d.; para = 1.5.2\r\n",
        " GEN 01,12: instruction = 48; ..; para = 1.5.2\r\n",
        " GEN 01,12: instruction = 49; .e; para = 1.5.2\r\n",
        " GEN 01,12: instruction = 50; d.; para = 1.5.2\r\n",
        " GEN 01,12: instruction = 51; .#; para = 1.5.3\r\n",
        " GEN 01,12: instruction = 52; ..; para = 1.5.3\r\n",
        " GEN 01,13: instruction = 53; .#; para = 1.5.3.1\r\n",
        " GEN 01,13: instruction = 54; .#; para = 1.5.3.2\r\n",
        " GEN 01,13: instruction = 55; ..; para = 1.5.3.2\r\n",
        " GEN 01,14: instruction = 56; .#; para = 1.6\r\n",
        " GEN 01,14: instruction = 57; .q; para = 1.6.1\r\n",
        " GEN 01,14: instruction = 58; ..; para = 1.6.1\r\n",
        " GEN 01,14: instruction = 59; ..; para = 1.6.1\r\n",
        " GEN 01,15: instruction = 60; ..; para = 1.6.1\r\n",
        " GEN 01,15: instruction = 61; ..; para = 1.6.1\r\n",
        " GEN 01,15: instruction = 62; ..; para = 1.6\r\n",
        " GEN 01,16: instruction = 63; .#; para = 1.6.2\r\n",
        " GEN 01,16: instruction = 64; l.; para = 1.6.2\r\n",
        " GEN 01,16: instruction = 65; l.; para = 1.6.2\r\n",
        " GEN 01,16: instruction = 66; l.; para = 1.6.2\r\n",
        " GEN 01,17: instruction = 67; .#; para = 1.6.2.1\r\n",
        " GEN 01,17: instruction = 68; ..; para = 1.6.2.1\r\n",
        " GEN 01,18: instruction = 69; ..; para = 1.6.2.1\r\n",
        " GEN 01,18: instruction = 70; ..; para = 1.6.2.1\r\n",
        " GEN 01,18: instruction = 71; .#; para = 1.6.3\r\n",
        " GEN 01,18: instruction = 72; ..; para = 1.6.3\r\n",
        " GEN 01,19: instruction = 73; .#; para = 1.6.3.1\r\n",
        " GEN 01,19: instruction = 74; .#; para = 1.6.3.2\r\n",
        " GEN 01,19: instruction = 75; ..; para = 1.6.3.2\r\n",
        " GEN 01,20: instruction = 76; .#; para = 1.7\r\n",
        " GEN 01,20: instruction = 77; .q; para = 1.7.1\r\n",
        " GEN 01,20: instruction = 78; ..; para = 1.7.1\r\n",
        " GEN 01,21: instruction = 79; .#; para = 1.7.2\r\n",
        " GEN 01,21: instruction = 80; ..; para = 1.7.2\r\n",
        " GEN 01,21: instruction = 81; ..; para = 1.7.2\r\n",
        " GEN 01,21: instruction = 82; .e; para = 1.7.2\r\n",
        " GEN 01,21: instruction = 83; d.; para = 1.7.2\r\n",
        " GEN 01,21: instruction = 84; l.; para = 1.7.2\r\n",
        " GEN 01,21: instruction = 85; .#; para = 1.7.3\r\n",
        " GEN 01,21: instruction = 86; ..; para = 1.7.3\r\n",
        " GEN 01,22: instruction = 87; .#; para = 1.7.3.1\r\n",
        " GEN 01,22: instruction = 88; ..; para = 1.7.3.1\r\n",
        " GEN 01,22: instruction = 89; .q; para = 1.7.3.1.1\r\n",
        " GEN 01,22: instruction = 90; ..; para = 1.7.3.1.1\r\n",
        " GEN 01,22: instruction = 91; ..; para = 1.7.3.1.1\r\n",
        " GEN 01,22: instruction = 92; ..; para = 1.7.3.1.1\r\n",
        " GEN 01,23: instruction = 93; .#; para = 1.7.3.2\r\n",
        " GEN 01,23: instruction = 94; .#; para = 1.7.3.3\r\n",
        " GEN 01,23: instruction = 95; ..; para = 1.7.3.3\r\n",
        " GEN 01,24: instruction = 96; .#; para = 1.8\r\n",
        " GEN 01,24: instruction = 97; .q; para = 1.8.1\r\n",
        " GEN 01,24: instruction = 98; l.; para = 1.8.1\r\n",
        " GEN 01,24: instruction = 99; ..; para = 1.8\r\n",
        " GEN 01,25: instruction = 100; .#; para = 1.8.2\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}