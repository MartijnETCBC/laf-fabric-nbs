{
 "metadata": {
  "name": "",
  "signature": "sha256:a0e2ac516d7c99a45294ebfbe7de6aead70ada9b864b8b265594fa083effcae8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
      "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
      "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Trees - for CALAP data (Syriac)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Starting LAF-Fabric"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "import laf\n",
      "from laf.fabric import LafFabric\n",
      "from etcbc.preprocess import prepare\n",
      "from etcbc.lib import Transcription\n",
      "fabric = LafFabric()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.2.6\n",
        "http://laf-fabric.readthedocs.org/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Declaring the features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tr = Transcription()\n",
      "fabric.load('calap', '--', 'trees', {\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": ('''\n",
      "        otype monads\n",
      "        surface_consonants\n",
      "        psp\n",
      "        phrase_type\n",
      "        verse_label\n",
      "    ''',''),\n",
      "    \"prepare\": prepare,\n",
      "}, verbose='NORMAL')\n",
      "exec(fabric.localnames.format(var='fabric'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s BEGIN COMPILE m: calap\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOGFILE=/Users/dirk/laf-fabric-data/calap/bin/__log__compile__.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s PARSING ANNOTATION FILES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.20s INFO: parsing calap_regions.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.62s INFO: parsing calap_monads.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.69s INFO: parsing calap_lingo.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    15s INFO: parsing calap_sections.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    16s INFO: parsing calap_monads.lex.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s INFO: parsing calap_lingo.ca.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s INFO: parsing calap_lingo.p.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    32s INFO: parsing calap_lingo.pa.xml\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    35s INFO: END PARSING\n",
        "    110714 good   regions  and     0 faulty ones\n",
        "    144485 linked nodes    and     0 unlinked ones\n",
        "      2871 good   edges    and     0 faulty ones\n",
        "    277559 good   annots   and     0 faulty ones\n",
        "   2244103 good   features and     0 faulty ones\n",
        "    535629 distinct xml identifiers\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    35s MODELING RESULT FILES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    35s INFO: XML-IDS (inverse mapping)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    35s INFO: NODES AND REGIONS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    35s INFO: NODES ANCHOR BOUNDARIES\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    37s INFO: NODES SORTING BY REGIONS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    37s INFO: NODES EVENTS\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    39s INFO: CONNECTIVITY\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    39s WRITING RESULT FILES for m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s END   COMPILE m: calap\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s INFO: DATA COMPILED AT: 2014-05-06T14-03-13\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    42s LOGFILE=/Users/dirk/laf-fabric-data/calap/tasks/trees/__log__trees.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    42s INFO: DATA LOADED FROM SOURCE calap AND ANNOX -- FOR TASK trees\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Configuration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we define the formatting of the trees.\n",
      "\n",
      "Relevant nodes\n",
      "--------------\n",
      "Not all nodes will be shown in the output.\n",
      "The nodes that are shown, have abbreviated names.\n",
      "Nodes with ``True`` will be shown, nodes with ``False`` will be suppressed.\n",
      "\n",
      "Suppressing a node leaves its children in place. Another way of looking at it, is: we replace a node by its children.\n",
      "\n",
      "Exception: when a node is visited twice, the second visit refers to the tree built by the first visit.\n",
      "In that case, we do not suppress the node.\n",
      "\n",
      "**N.B.** It turns out that the ``-atom`` nodes are never visited twice.\n",
      "\n",
      "pos_table\n",
      "---------\n",
      "We abbreviate the part-of-speech tags. \n",
      "We include the pos-info by inserting a unary node right above each word."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "relevant_nodes = [\n",
      "    (\"word\", '', True),\n",
      "    (\"phrase_atom\", 'Pa', False),\n",
      "    (\"phrase\", 'P', True),\n",
      "    (\"clause_atom\", 'C', True),\n",
      "]\n",
      "\n",
      "pos_table = {\n",
      " 'adjective': 'aj',\n",
      " 'adverb': 'av',\n",
      " 'conjunction': 'cj',\n",
      " 'interjection': 'ij',\n",
      " 'interrogative': 'ir',\n",
      " 'negative': 'ng',\n",
      " 'noun': 'n',\n",
      " 'preposition': 'pp',\n",
      " 'pronoun': 'pr',\n",
      " 'verb': 'vb',\n",
      "}\n",
      "\n",
      "select_node = set()\n",
      "select_type = set()\n",
      "abbrev_node = collections.defaultdict(lambda: None)\n",
      "\n",
      "for (otype, abb, relevant) in relevant_nodes:\n",
      "    if relevant:\n",
      "        select_node.add(abb)\n",
      "        select_type.add(otype)\n",
      "    abbrev_node[otype] = abb if abb != None else otype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur_stack = []\n",
      "parent = {}\n",
      "child = collections.defaultdict(lambda: [])\n",
      "l = 0\n",
      "for node in NN():\n",
      "    otype = F.otype.v(node)\n",
      "    relevant = otype in select_type\n",
      "    if not relevant: continue\n",
      "    l += 1\n",
      "    monads = F.monads.v(node)\n",
      "    m_set = set()\n",
      "    for i in monads.split(','):\n",
      "        bounds = i.split('-')\n",
      "        if len(bounds) == 2:\n",
      "            for j in range(int(bounds[0]), int(bounds[1]) + 1): m_set.add(j)\n",
      "        else: m_set.add(int(bounds[0]))\n",
      "    found = -1\n",
      "    ls = len(cur_stack)\n",
      "    for i in range(ls):\n",
      "        (snode, sm_set) = cur_stack[ls - i - 1]\n",
      "        if m_set <= sm_set:\n",
      "            parent[node] = snode\n",
      "            child[snode].append(node)\n",
      "            found = ls - i - 1\n",
      "            break;\n",
      "    if found != -1:\n",
      "        cur_stack = cur_stack[0:found + 1] + [(node, m_set)]\n",
      "    else:\n",
      "        cur_stack = [(node, m_set)]\n",
      "\n",
      "print(\"{} nodes, {} have parents and {} have children\".format(l, len(parent), len(child)))        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100226 nodes, 88760 have parents and 46298 have children\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Checking for sanity"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. How many clause_atom nodes? \n",
      "1. Does any clause_atom have a parent? \n",
      "1. Is every top node a clause_atom?\n",
      "1. Do you reach all clause_atoms if you go up from words?\n",
      "1. Do you reach all words if you go down from clause_atoms? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#1\n",
      "print(len(set(NN(test=F.otype.v, value='clause_atom'))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11411\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#2\n",
      "exceptions = set()\n",
      "for node in NN(test=F.otype.v, value='clause_atom'):\n",
      "    if node in parent: exceptions.add(node)\n",
      "if len(exceptions) == 0:\n",
      "    print(\"No clause_atom has a parent\")\n",
      "else:\n",
      "    print(\"{} clause_atoms have a parent:\".format(len(exceptions)))\n",
      "    for n in sorted(exceptions):\n",
      "        p = parent[n]\n",
      "        print(\"{} {} [{}] has {} parent {} [{}]\".format(\n",
      "            'clause_atom', n, F.monads.v(n), \n",
      "            F.otype.v(p), p, F.monads.v(p)\n",
      "        ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4 clause_atoms have a parent:\n",
        "clause_atom 53963 [257] has phrase parent 65481 [257,261,268]\n",
        "clause_atom 61449 [37049] has phrase parent 88611 [37049,37056]\n",
        "clause_atom 63071 [43736] has phrase parent 93449 [43736,43744-43745,43750-43751]\n",
        "clause_atom 64144 [48344] has phrase parent 96589 [48344,48346-48347]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#3 (check on #1)\n",
      "exceptions = collections.defaultdict(lambda: 0)\n",
      "ca = 0\n",
      "for node in NN():\n",
      "    otype = F.otype.v(node)\n",
      "    relevant = otype in select_type\n",
      "    if not relevant: continue\n",
      "    if otype == 'clause_atom': ca += 1\n",
      "    if node not in parent and otype != 'clause_atom': \n",
      "        exceptions[otype] += 1\n",
      "if len(exceptions) == 0:\n",
      "    print(\"All top nodes are clause_atoms\")\n",
      "else:\n",
      "    print(\"Top nodes which are not clause_atoms:\")\n",
      "    for t in sorted(exceptions): print(\"{}: {}x\".format(t, exceptions[t]))\n",
      "print(\"{} clause_atoms seen\".format(ca))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top nodes which are not clause_atoms:\n",
        "phrase: 51x\n",
        "word: 8x\n",
        "11411 clause_atoms seen\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#4\n",
      "def get_top(kind, rel, multi):\n",
      "    seen = set()\n",
      "    top_nodes = set()\n",
      "    start_nodes = set(NN(test=F.otype.v, value=kind))\n",
      "    next_nodes = start_nodes\n",
      "    print(\"Start with {} {} nodes\".format(len(start_nodes), kind))\n",
      "    while len(next_nodes):\n",
      "        new_next_nodes = set()\n",
      "        for node in next_nodes:\n",
      "            if node in seen: continue\n",
      "            seen.add(node)\n",
      "            if node in rel: \n",
      "                if multi:\n",
      "                    for c in rel[node]: new_next_nodes.add(c)\n",
      "                else:\n",
      "                    new_next_nodes.add(rel[node])\n",
      "            else: top_nodes.add(node)\n",
      "        next_nodes = new_next_nodes\n",
      "    top_types = collections.defaultdict(lambda: 0)\n",
      "    for t in top_nodes:\n",
      "        top_types[F.otype.v(t)] += 1\n",
      "    for t in top_types:\n",
      "        print(\"{}: {} topnodes\".format(t, top_types[t]))\n",
      "\n",
      "get_top('word', parent, False)\n",
      "get_top('clause_atom', child, True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Start with 53920 word nodes\n",
        "phrase: 51 topnodes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "clause_atom: 11399 topnodes\n",
        "word: 8 topnodes\n",
        "Start with 11411 clause_atom nodes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "word: 53834 topnodes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "clause_atom: 8 topnodes\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees = outfile(\"trees.txt\")\n",
      "\n",
      "nodes_seen = set()\n",
      "words = []\n",
      "sequential = []\n",
      "\n",
      "def write_tree(node):\n",
      "    if node in nodes_seen: return\n",
      "    nodes_seen.add(node)\n",
      "    otype = F.otype.v(node)\n",
      "    tag = abbrev_node[otype]\n",
      "    relevant = tag in select_node\n",
      "    if tag == 'P':\n",
      "        tag = F.phrase_type.v(node)\n",
      "    is_word = otype == 'word'\n",
      "    if is_word:\n",
      "        text = tr.to_syriac(F.surface_consonants.v(node))\n",
      "        pos = pos_table[F.psp.v(node)]\n",
      "        monad = int(F.monads.v(node))\n",
      "        sequential.append((\"W\", len(words)))\n",
      "        words.append((monad, text, pos))\n",
      "    else: sequential.append((\"O\" if relevant else \"N\", tag))\n",
      "    for ch in child[node]: write_tree(ch)\n",
      "    if not is_word: sequential.append((\"C\" if relevant else \"N\", tag))\n",
      "\n",
      "def do_sequential():\n",
      "    word_perm = {}\n",
      "    new_words = sorted(enumerate(words), key=lambda x: x[1][0])\n",
      "    word_reps = []\n",
      "    for (nn, (on, (monad, text, pos))) in enumerate(new_words):\n",
      "        word_perm[on] = nn\n",
      "        word_reps.append(text)\n",
      "    word_rep = ' '.join(word_reps)\n",
      "                    \n",
      "    for (code, info) in sequential:\n",
      "        if code == 'O' or code == 'C':\n",
      "            if code == 'O': trees.write('({}'.format(info))\n",
      "            else: trees.write(')')\n",
      "        elif code == 'W':\n",
      "            nn = word_perm[info]\n",
      "            pos = words[info][2]\n",
      "            trees.write('({} {})'.format(pos, nn))\n",
      "    trees.write(\"\\t{}\".format(word_rep))\n",
      "    \n",
      "msg(\"Writing trees ...\")\n",
      "verse_label = ''\n",
      "\n",
      "s = 0\n",
      "chunk = 1000\n",
      "sc = 0\n",
      "\n",
      "msg(\"making nodeset\")\n",
      "msg(\"processing topnodes\")\n",
      "for node in NN():\n",
      "    otype = F.otype.v(node)\n",
      "    relevant = otype in select_type\n",
      "    if  otype == 'verse':\n",
      "        verse_label = F.verse_label.v(node)\n",
      "        continue\n",
      "    if not relevant or node in parent: continue\n",
      "    nodes_seen = set()\n",
      "    sequential = []\n",
      "    words = []\n",
      "    write_tree(node)\n",
      "    do_sequential()\n",
      "    trees.write(\"\\t{}\\n\".format(verse_label))\n",
      "    s += 1\n",
      "    sc += 1\n",
      "    if sc == chunk:\n",
      "        msg(\"{} trees written\".format(s))\n",
      "        sc = 0\n",
      "    \n",
      "msg(\"{} trees written\".format(s))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s Writing trees ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s making nodeset\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s processing topnodes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s 1000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s 2000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s 3000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s 4000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s 5000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s 6000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s 7000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s 8000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s 9000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s 10000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s 11000 trees written\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    42s 11466 trees written\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    46s Results directory:\n",
        "/Users/dirk/laf-fabric-data/calap/tasks/trees\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "__log__trees.txt                        585 Tue May  6 16:03:59 2014\n",
        "trees.txt                            982393 Tue May  6 16:03:59 2014\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Preview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here are the first lines of the output."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 25 {my_file('trees.txt')}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(C(CP(cj 0))(NP(n 1)(n 2))(VP(vb 3)))\t\u0718 \u0721\u0720\u071f\u0710 \u0715\u0718\u071d\u0715 \u0723\u0710\u0712\t1R 1,1\r\n",
        "(C(CP(cj 0))(VP(vb 1))(PP(pp 2)(n 3)))\t\u0718 \u0725\u0720 \u0712 \u072b\u0722\u071d\u0710\t1R 1,1\r\n",
        "(C(CP(cj 0))(VP(vb 1))(VP(vb 2))(PP(pp 3))(PP(pp 4)(n 5)))\t\u0718 \u0721\u071f\u0723\u071d\u0722 \u0717\u0718\u0718 \u0720\u0717 \u0712 \u0720\u0712\u0718\u072b\u0710\t1R 1,1\r\n",
        "(C(CP(cj 0))(NegP(ng 1))(VP(vb 2)))\t\u0718 \u0720\u0710 \u072b\u071a\u0722\t1R 1,1\r\n",
        "(C(CP(cj 0))(VP(vb 1))(PP(pp 2))(NP(n 3)))\t\u0718 \u0710\u0721\u072a\u0718 \u0720\u0717 \u0725\u0712\u0715\u0718\u0717\u071d\t1R 1,2\r\n",
        "(C(InjP(ij 0))(NP(n 1)(pp 2))(VP(vb 3))(PP(pp 4)(n 5)(n 6))(NP(aj 7)(aj 8)))\t\u0717\u0710 \u0725\u0712\u0715\u071d\u071f \u0729\u0715\u0721\u071d\u071f \u0722\u0712\u0725\u0718\u0722 \u0720 \u0721\u072a\u0722 \u0721\u0720\u071f\u0710 \u0725\u0720\u071d\u0721\u072c\u0710 \u0712\u072c\u0718\u0720\u072c\u0710\t1R 1,2\r\n",
        "(C(CP(cj 0))(VP(vb 1))(PP(pp 2)(n 3)))\t\u0718 \u072c\u0729\u0718\u0721 \u0729\u0715\u0721 \u0721\u0720\u071f\u0710\t1R 1,2\r\n",
        "(C(CP(cj 0))(VP(vb 1))(PP(pp 2))(NP(aj 3)))\t\u0718 \u072c\u0717\u0718\u0710 \u0720\u0717 \u0721\u072b\u0721\u072b\u0722\u071d\u072c\u0710\t1R 1,2\r\n",
        "(C(CP(cj 0))(VP(vb 1))(PP(pp 2)(n 3)))\t\u0718 \u072c\u072b\u071f\u0712 \u0712 \u0725\u0718\u0712\u071f\t1R 1,2\r\n",
        "(C(CP(cj 0))(VP(vb 1))(PP(pp 2)(n 3)(n 4)))\t\u0718 \u0722\u072b\u071a\u0722 \u0720 \u0721\u072a\u0722 \u0721\u0720\u071f\u0710\t1R 1,2\r\n",
        "(C(CP(cj 0))(VP(vb 1))(NP(aj 2)))\t\u0718 \u0712\u0725\u0718 \u0725\u0720\u071d\u0721\u072c\u0710\t1R 1,3\r\n",
        "(C(CP(pp 0))(AdjP(aj 1)))\t\u0715 \u072b\u0726\u071d\u072a\u0710\t1R 1,3\r\n",
        "(C(PP(pp 0)(n 1)(n 2)(pp 3)(n 4)))\t\u0712 \u071f\u0720\u0717 \u072c\u071a\u0718\u0721\u0710 \u0715 \u0710\u071d\u0723\u072a\u071d\u0720\t1R 1,3\r\n",
        "(C(CP(cj 0))(VP(vb 1))(PP(pp 2)(n 3)(aj 4)))\t\u0718 \u0710\u072b\u071f\u071a\u0718 \u0720 \u0710\u0712\u071d\u072b\u0713 \u072b\u071d\u0720\u0718\u0721\u071d\u072c\u0710\t1R 1,3\r\n",
        "(C(CP(cj 0))(VP(vb 1))(PP(pp 2)(n 3)))\t\u0718 \u0710\u071d\u072c\u071d\u0718\u0717 \u0720 \u0721\u0720\u071f\u0710\t1R 1,3\r\n",
        "(C(CP(cj 0))(NP(aj 1))(VP(aj 2))(VP(vb 3))(PP(pp 4)(n 5))(AdjP(aj 6)))\t\u0718 \u0725\u0720\u071d\u0721\u072c\u0710 \u072b\u0726\u071d\u072a\u0710 \u0717\u0718\u072c \u0712 \u071a\u0719\u0718\u0717 \u071b\u0712\t1R 1,4\r\n",
        "(C(CP(cj 0))(VP(vb 1))(PP(pp 2)(n 3))(NP(aj 4)))\t\u0718 \u0717\u0718\u072c \u0720 \u0721\u0720\u071f\u0710 \u0721\u072b\u0721\u072b\u0722\u071d\u072c\u0710\t1R 1,4\r\n",
        "(C(CP(cj 0))(VP(vb 1))(PP(pp 2)))\t\u0718 \u0721\u072b\u0721\u072b\u0710 \u0720\u0717\t1R 1,4\r\n",
        "(C(CP(cj 0))(NP(n 1))(NegP(ng 2))(VP(vb 3)))\t\u0718 \u0721\u0720\u071f\u0710 \u0720\u0710 \u071d\u0715\u0725\u0717\t1R 1,4\r\n",
        "(C(CP(cj 0))(PrNP(n 1))(n 2)(n 3)(VP(vb 4)))\t\u0718 \u0710\u0715\u0718\u0722\u071d\u0710 \u0712\u072a \u071a\u0713\u071d\u072c \u0721\u072c\u072a\u0718\u072a\u0712\t1R 1,5\r\n",
        "(C(CP(cj 0))(VP(vb 1)))\t\u0718 \u0710\u0721\u072a\t1R 1,5\r\n",
        "(C(PPrP(pr 0))(VP(vb 1)))\t\u0710\u0722\u0710 \u0710\u0721\u0720\u071f\t1R 1,5\r\n",
        "(C(CP(cj 0))(VP(vb 1))(PP(pp 2))(NP(n 3)(cj 4)(n 5)(cj 6)(n 7)(n 8)))\t\u0718 \u0725\u0712\u0715 \u0720\u0717 \u0721\u072a\u071f\u0712\u072c\u0710 \u0718 \u0726\u072a\u072b\u0710 \u0718 \u071a\u0721\u072b\u071d\u0722 \u0713\u0712\u072a\u071d\u0722\t1R 1,5\r\n",
        "(C(CP(pp 0))(VP(vb 1))(VP(vb 2))(PP(pp 3)))\t\u0715 \u072a\u0717\u071b\u071d\u0722 \u0717\u0718\u0718 \u0729\u0715\u0721\u0718\u0717\u071d\t1R 1,5\r\n",
        "(C(CP(cj 0))(NegP(ng 1))(VP(vb 2))(PP(pp 3))(NP(n 4))(PP(pp 5)(n 6)))\t\u0718 \u0720\u0710 \u071f\u0710\u0710 \u0712\u0717 \u0710\u0712\u0718\u0717\u071d \u0721\u0722 \u071d\u0718\u0721\u0718\u0717\u071d\t1R 1,6\r\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}